{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "「PyTorch 框架計算損失函數以及更新參數_HW9.ipynb」的副本",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmywang2/NLP/blob/main/PyTorch_%E6%A1%86%E6%9E%B6%E8%A8%88%E7%AE%97%E6%90%8D%E5%A4%B1%E5%87%BD%E6%95%B8%E4%BB%A5%E5%8F%8A%E6%9B%B4%E6%96%B0%E5%8F%83%E6%95%B8_HW9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy0KCZtnPJf4"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QeTFbeCPJf9"
      },
      "source": [
        "### 搭建模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaE3UpIWPJf9"
      },
      "source": [
        "class LinearBNAC(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bias=True, dropout=0.3, is_output=False):\n",
        "        super(LinearBNAC, self).__init__()\n",
        "        if is_output and out_channels==1:\n",
        "            self.linear = nn.Sequential(\n",
        "                nn.Linear(in_channels, out_channels, bias=bias),\n",
        "                nn.Sigmoid()\n",
        "            )\n",
        "        elif is_output:\n",
        "            self.linear = nn.Sequential(\n",
        "                nn.Linear(in_channels, out_channels, bias=bias),\n",
        "                nn.Softmax(dim=1)\n",
        "            )   \n",
        "        else:\n",
        "            self.linear = nn.Sequential(\n",
        "                nn.Linear(in_channels, out_channels, bias=bias),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.BatchNorm1d(out_channels),\n",
        "                nn.LeakyReLU(inplace=True)\n",
        "            )\n",
        "            \n",
        "    def forward(self, x):\n",
        "        out=self.linear(x)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcHJRn0BPJf-"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dimention, output_classes=1):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = LinearBNAC(input_dimention, 128)\n",
        "        self.layer2 = LinearBNAC(128, 64)\n",
        "        self.layer3 = LinearBNAC(64, 32)\n",
        "        self.output = LinearBNAC(32, output_classes, is_output=True)\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.output(x)\n",
        "        return x \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXUn03jtPJf-"
      },
      "source": [
        "### 準備輸入資料、優化器、標籤資料、模型輸出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xOvUyQWPJf-"
      },
      "source": [
        "model = Model(input_dimention=256,output_classes=10)\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=1e-3, weight_decay=1e-3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wdVDcMdPJf_"
      },
      "source": [
        "batch_size = 4\n",
        "input_features = 256\n",
        "dummy_input = torch.randn(batch_size, input_features,)\n",
        "\n",
        "#target = torch.empty(4, dtype=torch.float).random_(10)\n",
        "target = torch.tensor([9., 5., 4., 4.], dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceFyrbiaPJf_",
        "outputId": "82ff44ae-c153-4180-ebcb-3f49a9e56a99"
      },
      "source": [
        "output = model(dummy_input)\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0575, 0.1173, 0.1355, 0.1671, 0.0946, 0.0714, 0.0804, 0.1449, 0.0494,\n",
            "         0.0819],\n",
            "        [0.0873, 0.1133, 0.0622, 0.0987, 0.1071, 0.1449, 0.0644, 0.1380, 0.0715,\n",
            "         0.1127],\n",
            "        [0.1059, 0.1363, 0.0724, 0.1000, 0.1285, 0.0855, 0.0517, 0.1073, 0.0609,\n",
            "         0.1513],\n",
            "        [0.1411, 0.0949, 0.0672, 0.1434, 0.1396, 0.0872, 0.0750, 0.1328, 0.0822,\n",
            "         0.0365]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geAMeWuyPJgA"
      },
      "source": [
        "### 計算 CrossEntropy Loss\n",
        "* 請注意哪一個 Loss最適合：我們已經使用 softmax\n",
        "* 因為我們有使用dropout，並隨機產生dummy_input，所以各為學員得到的值會與解答不同，然而步驟原理需要相同"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi7HtH6FPJgA"
      },
      "source": [
        "from torch.nn import NLLLoss, LogSoftmax, CrossEntropyLoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X2giZbJPJgA"
      },
      "source": [
        "criterion = NLLLoss() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiIueckNPJgA"
      },
      "source": [
        "loss = criterion(torch.log(output), target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz9NWLZqPJgA"
      },
      "source": [
        "### 完成back propagation並更新梯度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPUpfD2bPJgB"
      },
      "source": [
        "loss.backward()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f39o7K3CPJgB",
        "outputId": "98ce5f83-d576-499b-e5df-0f2f684133c7"
      },
      "source": [
        "print('weight : {}'.format(model.layer1.linear[0].weight))\n",
        "print('\\n')\n",
        "print('grad : {}'.format(model.layer1.linear[0].weight.grad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight : Parameter containing:\n",
            "tensor([[-0.0200, -0.0541, -0.0286,  ...,  0.0084,  0.0547,  0.0107],\n",
            "        [-0.0070,  0.0466,  0.0557,  ..., -0.0375,  0.0325,  0.0253],\n",
            "        [ 0.0326,  0.0096, -0.0434,  ..., -0.0078, -0.0206,  0.0448],\n",
            "        ...,\n",
            "        [-0.0371,  0.0088, -0.0537,  ...,  0.0086,  0.0210,  0.0212],\n",
            "        [ 0.0096,  0.0484,  0.0464,  ..., -0.0415, -0.0260,  0.0489],\n",
            "        [-0.0255,  0.0090, -0.0460,  ..., -0.0230,  0.0444,  0.0168]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\n",
            "grad : tensor([[ 2.6608e-04, -5.1024e-05, -1.6257e-04,  ...,  8.3882e-05,\n",
            "         -2.2236e-04, -6.7840e-05],\n",
            "        [-5.1933e-02, -1.1145e-03,  5.7692e-02,  ...,  6.2620e-02,\n",
            "          2.0801e-02, -6.5721e-02],\n",
            "        [-6.8930e-04,  3.8470e-04,  6.6275e-04,  ...,  1.8281e-04,\n",
            "         -4.2427e-04,  9.5983e-04],\n",
            "        ...,\n",
            "        [-2.3458e-02, -3.1425e-03,  3.2352e-02,  ...,  2.7947e-02,\n",
            "          2.4986e-02, -4.0178e-02],\n",
            "        [ 1.2301e-02, -1.8653e-03, -2.4341e-02,  ..., -2.4919e-02,\n",
            "          1.6848e-03,  1.2487e-02],\n",
            "        [ 1.3871e-02,  5.4290e-03, -2.0456e-02,  ..., -7.9840e-03,\n",
            "         -3.7071e-02,  3.3927e-02]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmZ9GGTgPJgB"
      },
      "source": [
        "optimizer.step()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0iEka7uPJgB",
        "outputId": "3ec3dd30-ad0e-48a5-b3ef-ef7cd091c502"
      },
      "source": [
        "print('weight : {}'.format(model.layer1.linear[0].weight))\n",
        "print('\\n')\n",
        "print('grad : {}'.format(model.layer1.linear[0].weight.grad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight : Parameter containing:\n",
            "tensor([[-0.0210, -0.0531, -0.0276,  ...,  0.0074,  0.0557,  0.0117],\n",
            "        [-0.0060,  0.0476,  0.0547,  ..., -0.0385,  0.0315,  0.0263],\n",
            "        [ 0.0336,  0.0086, -0.0444,  ..., -0.0088, -0.0196,  0.0438],\n",
            "        ...,\n",
            "        [-0.0361,  0.0098, -0.0547,  ...,  0.0076,  0.0200,  0.0222],\n",
            "        [ 0.0086,  0.0494,  0.0474,  ..., -0.0405, -0.0270,  0.0479],\n",
            "        [-0.0265,  0.0080, -0.0450,  ..., -0.0220,  0.0454,  0.0158]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\n",
            "grad : tensor([[ 2.6608e-04, -5.1024e-05, -1.6257e-04,  ...,  8.3882e-05,\n",
            "         -2.2236e-04, -6.7840e-05],\n",
            "        [-5.1933e-02, -1.1145e-03,  5.7692e-02,  ...,  6.2620e-02,\n",
            "          2.0801e-02, -6.5721e-02],\n",
            "        [-6.8930e-04,  3.8470e-04,  6.6275e-04,  ...,  1.8281e-04,\n",
            "         -4.2427e-04,  9.5983e-04],\n",
            "        ...,\n",
            "        [-2.3458e-02, -3.1425e-03,  3.2352e-02,  ...,  2.7947e-02,\n",
            "          2.4986e-02, -4.0178e-02],\n",
            "        [ 1.2301e-02, -1.8653e-03, -2.4341e-02,  ..., -2.4919e-02,\n",
            "          1.6848e-03,  1.2487e-02],\n",
            "        [ 1.3871e-02,  5.4290e-03, -2.0456e-02,  ..., -7.9840e-03,\n",
            "         -3.7071e-02,  3.3927e-02]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd1oVSfpPJgB"
      },
      "source": [
        "### 清空 gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyudM0xRPJgC"
      },
      "source": [
        "optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KG9NRr8PJgC",
        "outputId": "28702a6e-68f3-479a-dfa6-69d52e759eb6"
      },
      "source": [
        "print('weight : {}'.format(model.layer1.linear[0].weight))\n",
        "print('\\n')\n",
        "print('grad : {}'.format(model.layer1.linear[0].weight.grad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight : Parameter containing:\n",
            "tensor([[-0.0210, -0.0531, -0.0276,  ...,  0.0074,  0.0557,  0.0117],\n",
            "        [-0.0060,  0.0476,  0.0547,  ..., -0.0385,  0.0315,  0.0263],\n",
            "        [ 0.0336,  0.0086, -0.0444,  ..., -0.0088, -0.0196,  0.0438],\n",
            "        ...,\n",
            "        [-0.0361,  0.0098, -0.0547,  ...,  0.0076,  0.0200,  0.0222],\n",
            "        [ 0.0086,  0.0494,  0.0474,  ..., -0.0405, -0.0270,  0.0479],\n",
            "        [-0.0265,  0.0080, -0.0450,  ..., -0.0220,  0.0454,  0.0158]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\n",
            "grad : tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyCVWspGQ6hB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}