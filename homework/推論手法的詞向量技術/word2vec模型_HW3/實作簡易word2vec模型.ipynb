{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的: 實作word2vec Skip-gram模型\n",
    "在課程中了解如何搭建CBOW模型，這次的作業目的在於透過搭建Skip-gram模型來了解另外一種word2vec的架構。\n",
    "\n",
    "Hint_1: 學員可以善用課程中以搭建好的function模組\n",
    "Hint_2: Skip_gram所需的輸入資料與目標跟CBOW有些許不同，Skip_gram是由中間字詞預測上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from utils.utility import clip_grads, convert_one_hot, preprocess, Trainer\n",
    "from utils.layers import Dense, SoftmaxWithCrossEntropy\n",
    "from utils.optimizer import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7, 0, 4, 1, 3, 5]),\n",
       " array([[2, 0],\n",
       "        [7, 4],\n",
       "        [0, 1],\n",
       "        [4, 3],\n",
       "        [1, 5],\n",
       "        [3, 6]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same corpus as in the lecture\n",
    "text = \"I am studying Natural Language Processing now.\"\n",
    "\n",
    "# define create_contexts_target function\n",
    "def create_contexts_target(corpus: List, window_size: int=1):\n",
    "\n",
    "    contexts = corpus[window_size:-window_size]\n",
    "    targets = []\n",
    "\n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size + 1):\n",
    "            if t == 0:\n",
    "                # skip target word itself\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        targets.append(cs)\n",
    "\n",
    "    return np.array(contexts), np.array(targets)\n",
    "\n",
    "# transform corpus to contexts and targets pair\n",
    "corpus, word2idx, idx2word = preprocess([text])\n",
    "contexts, targets= create_contexts_target(corpus[0], window_size=1)\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0]], dtype=int32),\n",
       " array([[[0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0]],\n",
       " \n",
       "        [[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0]]], dtype=int32))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform contexts and targets to one-hot encoding\n",
    "contexts = convert_one_hot(contexts, len(word2idx))\n",
    "targets = convert_one_hot(targets, len(word2idx))\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Skip-gram model\n",
    "class SkipGram:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # initialize weights\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        # create layers\n",
    "        self.in_layer = Dense(W_in)\n",
    "        self.out_layer = Dense(W_out)\n",
    "        self.loss_layers = [SoftmaxWithCrossEntropy() for i in range(window_size*2)]\n",
    "        \n",
    "\n",
    "        layers = [self.in_layer, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "        # word vector matrix\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, targets):\n",
    "        h = self.in_layer.forward(contexts)\n",
    "        s = self.out_layer.forward(h)\n",
    "        \n",
    "        loss = sum([self.loss_layers[i].forward(s, targets[:, i]) for i in range(self.window_size*2)])\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        \n",
    "        ds = sum([self.loss_layers[i].backward(dout) for i in range(self.window_size*2)])\n",
    "        dh = self.out_layer.backward(ds)\n",
    "        self.in_layer.backward(dh)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 329/1000 [00:00<00:00, 1464.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 1/2, Loss: 4.1586910819777785\n",
      "Epoch: 2, Iteration: 1/2, Loss: 4.158875059019992\n",
      "Epoch: 3, Iteration: 1/2, Loss: 4.1587947430305245\n",
      "Epoch: 4, Iteration: 1/2, Loss: 4.158706387507609\n",
      "Epoch: 5, Iteration: 1/2, Loss: 4.158601974477122\n",
      "Epoch: 6, Iteration: 1/2, Loss: 4.158583270857286\n",
      "Epoch: 7, Iteration: 1/2, Loss: 4.158635420263096\n",
      "Epoch: 8, Iteration: 1/2, Loss: 4.158495154919667\n",
      "Epoch: 9, Iteration: 1/2, Loss: 4.158232185439199\n",
      "Epoch: 10, Iteration: 1/2, Loss: 4.158522441042009\n",
      "Epoch: 11, Iteration: 1/2, Loss: 4.158043633612113\n",
      "Epoch: 12, Iteration: 1/2, Loss: 4.158148220384539\n",
      "Epoch: 13, Iteration: 1/2, Loss: 4.157967814661137\n",
      "Epoch: 14, Iteration: 1/2, Loss: 4.158081680875081\n",
      "Epoch: 15, Iteration: 1/2, Loss: 4.157713913887963\n",
      "Epoch: 16, Iteration: 1/2, Loss: 4.157624306041391\n",
      "Epoch: 17, Iteration: 1/2, Loss: 4.157444196414943\n",
      "Epoch: 18, Iteration: 1/2, Loss: 4.157418910248838\n",
      "Epoch: 19, Iteration: 1/2, Loss: 4.157076235211435\n",
      "Epoch: 20, Iteration: 1/2, Loss: 4.15712576128405\n",
      "Epoch: 21, Iteration: 1/2, Loss: 4.156766471849796\n",
      "Epoch: 22, Iteration: 1/2, Loss: 4.156467277804584\n",
      "Epoch: 23, Iteration: 1/2, Loss: 4.15631956976096\n",
      "Epoch: 24, Iteration: 1/2, Loss: 4.155454139148158\n",
      "Epoch: 25, Iteration: 1/2, Loss: 4.15591087275402\n",
      "Epoch: 26, Iteration: 1/2, Loss: 4.154766347729375\n",
      "Epoch: 27, Iteration: 1/2, Loss: 4.155156445651791\n",
      "Epoch: 28, Iteration: 1/2, Loss: 4.1543571653177285\n",
      "Epoch: 29, Iteration: 1/2, Loss: 4.153673148053279\n",
      "Epoch: 30, Iteration: 1/2, Loss: 4.153707455146094\n",
      "Epoch: 31, Iteration: 1/2, Loss: 4.151800849031312\n",
      "Epoch: 32, Iteration: 1/2, Loss: 4.151740041758207\n",
      "Epoch: 33, Iteration: 1/2, Loss: 4.150977507211281\n",
      "Epoch: 34, Iteration: 1/2, Loss: 4.149960211470552\n",
      "Epoch: 35, Iteration: 1/2, Loss: 4.149577419763416\n",
      "Epoch: 36, Iteration: 1/2, Loss: 4.146430477670208\n",
      "Epoch: 37, Iteration: 1/2, Loss: 4.14694664559393\n",
      "Epoch: 38, Iteration: 1/2, Loss: 4.145209845934901\n",
      "Epoch: 39, Iteration: 1/2, Loss: 4.142550364550991\n",
      "Epoch: 40, Iteration: 1/2, Loss: 4.142801802048857\n",
      "Epoch: 41, Iteration: 1/2, Loss: 4.139209926920728\n",
      "Epoch: 42, Iteration: 1/2, Loss: 4.138347349081251\n",
      "Epoch: 43, Iteration: 1/2, Loss: 4.131647825654073\n",
      "Epoch: 44, Iteration: 1/2, Loss: 4.134871238825371\n",
      "Epoch: 45, Iteration: 1/2, Loss: 4.128227210646713\n",
      "Epoch: 46, Iteration: 1/2, Loss: 4.123138594957991\n",
      "Epoch: 47, Iteration: 1/2, Loss: 4.120215093959868\n",
      "Epoch: 48, Iteration: 1/2, Loss: 4.1178561111370104\n",
      "Epoch: 49, Iteration: 1/2, Loss: 4.114578938603266\n",
      "Epoch: 50, Iteration: 1/2, Loss: 4.107355428505858\n",
      "Epoch: 51, Iteration: 1/2, Loss: 4.102207790171531\n",
      "Epoch: 52, Iteration: 1/2, Loss: 4.091299224341819\n",
      "Epoch: 53, Iteration: 1/2, Loss: 4.088486423155166\n",
      "Epoch: 54, Iteration: 1/2, Loss: 4.0743737850462605\n",
      "Epoch: 55, Iteration: 1/2, Loss: 4.068441238926578\n",
      "Epoch: 56, Iteration: 1/2, Loss: 4.047238455244238\n",
      "Epoch: 57, Iteration: 1/2, Loss: 4.059519062690542\n",
      "Epoch: 58, Iteration: 1/2, Loss: 4.033151542073769\n",
      "Epoch: 59, Iteration: 1/2, Loss: 3.9993632278696847\n",
      "Epoch: 60, Iteration: 1/2, Loss: 4.022372998529535\n",
      "Epoch: 61, Iteration: 1/2, Loss: 3.9666167088561632\n",
      "Epoch: 62, Iteration: 1/2, Loss: 3.9673758403792374\n",
      "Epoch: 63, Iteration: 1/2, Loss: 3.928963408843024\n",
      "Epoch: 64, Iteration: 1/2, Loss: 3.9297658003110585\n",
      "Epoch: 65, Iteration: 1/2, Loss: 3.8906768898973403\n",
      "Epoch: 66, Iteration: 1/2, Loss: 3.861604040730225\n",
      "Epoch: 67, Iteration: 1/2, Loss: 3.8230752038195566\n",
      "Epoch: 68, Iteration: 1/2, Loss: 3.834670855892411\n",
      "Epoch: 69, Iteration: 1/2, Loss: 3.7581003793804575\n",
      "Epoch: 70, Iteration: 1/2, Loss: 3.7068613714369514\n",
      "Epoch: 71, Iteration: 1/2, Loss: 3.7427358700257445\n",
      "Epoch: 72, Iteration: 1/2, Loss: 3.69352158851472\n",
      "Epoch: 73, Iteration: 1/2, Loss: 3.5638079431269105\n",
      "Epoch: 74, Iteration: 1/2, Loss: 3.5645124401149184\n",
      "Epoch: 75, Iteration: 1/2, Loss: 3.4667068527002187\n",
      "Epoch: 76, Iteration: 1/2, Loss: 3.5169883076026145\n",
      "Epoch: 77, Iteration: 1/2, Loss: 3.435938968684156\n",
      "Epoch: 78, Iteration: 1/2, Loss: 3.3466802843420584\n",
      "Epoch: 79, Iteration: 1/2, Loss: 3.35155409304284\n",
      "Epoch: 80, Iteration: 1/2, Loss: 3.219067155260298\n",
      "Epoch: 81, Iteration: 1/2, Loss: 3.1375799600958527\n",
      "Epoch: 82, Iteration: 1/2, Loss: 3.1516259053712483\n",
      "Epoch: 83, Iteration: 1/2, Loss: 3.1607935381031895\n",
      "Epoch: 84, Iteration: 1/2, Loss: 3.0263498166079636\n",
      "Epoch: 85, Iteration: 1/2, Loss: 3.084441127248649\n",
      "Epoch: 86, Iteration: 1/2, Loss: 2.909478808523878\n",
      "Epoch: 87, Iteration: 1/2, Loss: 2.954745956192173\n",
      "Epoch: 88, Iteration: 1/2, Loss: 2.8400677760236315\n",
      "Epoch: 89, Iteration: 1/2, Loss: 2.7611236108453143\n",
      "Epoch: 90, Iteration: 1/2, Loss: 2.8095984947743764\n",
      "Epoch: 91, Iteration: 1/2, Loss: 2.7031668611211264\n",
      "Epoch: 92, Iteration: 1/2, Loss: 2.701607582776191\n",
      "Epoch: 93, Iteration: 1/2, Loss: 2.5959193595545544\n",
      "Epoch: 94, Iteration: 1/2, Loss: 2.6337881387106767\n",
      "Epoch: 95, Iteration: 1/2, Loss: 2.4517105195235818\n",
      "Epoch: 96, Iteration: 1/2, Loss: 2.6030910701968164\n",
      "Epoch: 97, Iteration: 1/2, Loss: 2.482078668887222\n",
      "Epoch: 98, Iteration: 1/2, Loss: 2.330152872000904\n",
      "Epoch: 99, Iteration: 1/2, Loss: 2.456501846245074\n",
      "Epoch: 100, Iteration: 1/2, Loss: 2.439130058118332\n",
      "Epoch: 101, Iteration: 1/2, Loss: 2.3172196057781633\n",
      "Epoch: 102, Iteration: 1/2, Loss: 2.285544967274327\n",
      "Epoch: 103, Iteration: 1/2, Loss: 2.370284909202989\n",
      "Epoch: 104, Iteration: 1/2, Loss: 2.212165311753205\n",
      "Epoch: 105, Iteration: 1/2, Loss: 2.137743240373878\n",
      "Epoch: 106, Iteration: 1/2, Loss: 2.3234154179452595\n",
      "Epoch: 107, Iteration: 1/2, Loss: 2.153426934040983\n",
      "Epoch: 108, Iteration: 1/2, Loss: 2.0907139340851066\n",
      "Epoch: 109, Iteration: 1/2, Loss: 2.169248933933474\n",
      "Epoch: 110, Iteration: 1/2, Loss: 2.0648696469403545\n",
      "Epoch: 111, Iteration: 1/2, Loss: 2.1191005299940207\n",
      "Epoch: 112, Iteration: 1/2, Loss: 2.0017073769587808\n",
      "Epoch: 113, Iteration: 1/2, Loss: 2.0702000987110565\n",
      "Epoch: 114, Iteration: 1/2, Loss: 1.9753529339725893\n",
      "Epoch: 115, Iteration: 1/2, Loss: 2.0574436315352855\n",
      "Epoch: 116, Iteration: 1/2, Loss: 1.891088902752399\n",
      "Epoch: 117, Iteration: 1/2, Loss: 1.983406945011467\n",
      "Epoch: 118, Iteration: 1/2, Loss: 1.935825559422765\n",
      "Epoch: 119, Iteration: 1/2, Loss: 1.9375908517420464\n",
      "Epoch: 120, Iteration: 1/2, Loss: 1.9081259439120317\n",
      "Epoch: 121, Iteration: 1/2, Loss: 1.8919801651634038\n",
      "Epoch: 122, Iteration: 1/2, Loss: 1.85309497246095\n",
      "Epoch: 123, Iteration: 1/2, Loss: 1.8371177264579202\n",
      "Epoch: 124, Iteration: 1/2, Loss: 1.8917042725458613\n",
      "Epoch: 125, Iteration: 1/2, Loss: 1.8152816938486964\n",
      "Epoch: 126, Iteration: 1/2, Loss: 1.7945725284105025\n",
      "Epoch: 127, Iteration: 1/2, Loss: 1.817364269455601\n",
      "Epoch: 128, Iteration: 1/2, Loss: 1.7911371483870806\n",
      "Epoch: 129, Iteration: 1/2, Loss: 1.7841246498298151\n",
      "Epoch: 130, Iteration: 1/2, Loss: 1.7856297209892364\n",
      "Epoch: 131, Iteration: 1/2, Loss: 1.7126777052479472\n",
      "Epoch: 132, Iteration: 1/2, Loss: 1.7874281152172329\n",
      "Epoch: 133, Iteration: 1/2, Loss: 1.7095207649466313\n",
      "Epoch: 134, Iteration: 1/2, Loss: 1.732861980606393\n",
      "Epoch: 135, Iteration: 1/2, Loss: 1.7325523805352523\n",
      "Epoch: 136, Iteration: 1/2, Loss: 1.7068070973755085\n",
      "Epoch: 137, Iteration: 1/2, Loss: 1.7177869403417396\n",
      "Epoch: 138, Iteration: 1/2, Loss: 1.7045835589594769\n",
      "Epoch: 139, Iteration: 1/2, Loss: 1.640356886614208\n",
      "Epoch: 140, Iteration: 1/2, Loss: 1.7196068828091609\n",
      "Epoch: 141, Iteration: 1/2, Loss: 1.677278694866542\n",
      "Epoch: 142, Iteration: 1/2, Loss: 1.6491783274379839\n",
      "Epoch: 143, Iteration: 1/2, Loss: 1.6477974151831956\n",
      "Epoch: 144, Iteration: 1/2, Loss: 1.6608163056618834\n",
      "Epoch: 145, Iteration: 1/2, Loss: 1.6427774961641948\n",
      "Epoch: 146, Iteration: 1/2, Loss: 1.6388618356929683\n",
      "Epoch: 147, Iteration: 1/2, Loss: 1.6329503414379216\n",
      "Epoch: 148, Iteration: 1/2, Loss: 1.6305227400122535\n",
      "Epoch: 149, Iteration: 1/2, Loss: 1.6191022239028796\n",
      "Epoch: 150, Iteration: 1/2, Loss: 1.6155783778690918\n",
      "Epoch: 151, Iteration: 1/2, Loss: 1.6171350672782248\n",
      "Epoch: 152, Iteration: 1/2, Loss: 1.6151586300802736\n",
      "Epoch: 153, Iteration: 1/2, Loss: 1.5752617291863804\n",
      "Epoch: 154, Iteration: 1/2, Loss: 1.5981191358125084\n",
      "Epoch: 155, Iteration: 1/2, Loss: 1.612998348474064\n",
      "Epoch: 156, Iteration: 1/2, Loss: 1.5726540865288994\n",
      "Epoch: 157, Iteration: 1/2, Loss: 1.6016780551416325\n",
      "Epoch: 158, Iteration: 1/2, Loss: 1.5660217556268896\n",
      "Epoch: 159, Iteration: 1/2, Loss: 1.5710155503388703\n",
      "Epoch: 160, Iteration: 1/2, Loss: 1.5906503001733394\n",
      "Epoch: 161, Iteration: 1/2, Loss: 1.5636806363752553\n",
      "Epoch: 162, Iteration: 1/2, Loss: 1.5512904778558494\n",
      "Epoch: 163, Iteration: 1/2, Loss: 1.56494331465109\n",
      "Epoch: 164, Iteration: 1/2, Loss: 1.5463685587763472\n",
      "Epoch: 165, Iteration: 1/2, Loss: 1.578249613514477\n",
      "Epoch: 166, Iteration: 1/2, Loss: 1.5375320126375414\n",
      "Epoch: 167, Iteration: 1/2, Loss: 1.5562301138432457\n",
      "Epoch: 168, Iteration: 1/2, Loss: 1.5362031471407231\n",
      "Epoch: 169, Iteration: 1/2, Loss: 1.5385358426942055\n",
      "Epoch: 170, Iteration: 1/2, Loss: 1.544123117176572\n",
      "Epoch: 171, Iteration: 1/2, Loss: 1.5350056356940516\n",
      "Epoch: 172, Iteration: 1/2, Loss: 1.5337297515696586\n",
      "Epoch: 173, Iteration: 1/2, Loss: 1.5380050880613647\n",
      "Epoch: 174, Iteration: 1/2, Loss: 1.527780192164357\n",
      "Epoch: 175, Iteration: 1/2, Loss: 1.5106955425683024\n",
      "Epoch: 176, Iteration: 1/2, Loss: 1.531906574726932\n",
      "Epoch: 177, Iteration: 1/2, Loss: 1.5178787156771731\n",
      "Epoch: 178, Iteration: 1/2, Loss: 1.5232743181606172\n",
      "Epoch: 179, Iteration: 1/2, Loss: 1.5119992945292906\n",
      "Epoch: 180, Iteration: 1/2, Loss: 1.51718456368218\n",
      "Epoch: 181, Iteration: 1/2, Loss: 1.5029803049669554\n",
      "Epoch: 182, Iteration: 1/2, Loss: 1.5281512052090254\n",
      "Epoch: 183, Iteration: 1/2, Loss: 1.5056871381411134\n",
      "Epoch: 184, Iteration: 1/2, Loss: 1.510307842963585\n",
      "Epoch: 185, Iteration: 1/2, Loss: 1.4938175244143403\n",
      "Epoch: 186, Iteration: 1/2, Loss: 1.499001838093874\n",
      "Epoch: 187, Iteration: 1/2, Loss: 1.5110263721866208\n",
      "Epoch: 188, Iteration: 1/2, Loss: 1.4864312086774538\n",
      "Epoch: 189, Iteration: 1/2, Loss: 1.5072495577191107\n",
      "Epoch: 190, Iteration: 1/2, Loss: 1.4994599132927744\n",
      "Epoch: 191, Iteration: 1/2, Loss: 1.4892643127688872\n",
      "Epoch: 192, Iteration: 1/2, Loss: 1.4961696471003405\n",
      "Epoch: 193, Iteration: 1/2, Loss: 1.4766504172329813\n",
      "Epoch: 194, Iteration: 1/2, Loss: 1.4938450095623759\n",
      "Epoch: 195, Iteration: 1/2, Loss: 1.4869352586352405\n",
      "Epoch: 196, Iteration: 1/2, Loss: 1.4866279355838252\n",
      "Epoch: 197, Iteration: 1/2, Loss: 1.4856099417029252\n",
      "Epoch: 198, Iteration: 1/2, Loss: 1.4876530557191963\n",
      "Epoch: 199, Iteration: 1/2, Loss: 1.4784554113168573\n",
      "Epoch: 200, Iteration: 1/2, Loss: 1.475976048006702\n",
      "Epoch: 201, Iteration: 1/2, Loss: 1.48983764042608\n",
      "Epoch: 202, Iteration: 1/2, Loss: 1.4618051123264217\n",
      "Epoch: 203, Iteration: 1/2, Loss: 1.4902548016299084\n",
      "Epoch: 204, Iteration: 1/2, Loss: 1.4703762704297676\n",
      "Epoch: 205, Iteration: 1/2, Loss: 1.4776816351323185\n",
      "Epoch: 206, Iteration: 1/2, Loss: 1.4759674660141993\n",
      "Epoch: 207, Iteration: 1/2, Loss: 1.458285293622783\n",
      "Epoch: 208, Iteration: 1/2, Loss: 1.4828190994846429\n",
      "Epoch: 209, Iteration: 1/2, Loss: 1.463000522106336\n",
      "Epoch: 210, Iteration: 1/2, Loss: 1.4710080115410045\n",
      "Epoch: 211, Iteration: 1/2, Loss: 1.4707966201793468\n",
      "Epoch: 212, Iteration: 1/2, Loss: 1.4600953643310368\n",
      "Epoch: 213, Iteration: 1/2, Loss: 1.4636457089925767\n",
      "Epoch: 214, Iteration: 1/2, Loss: 1.4680009195915726\n",
      "Epoch: 215, Iteration: 1/2, Loss: 1.4643669714360676\n",
      "Epoch: 216, Iteration: 1/2, Loss: 1.4557181148669684\n",
      "Epoch: 217, Iteration: 1/2, Loss: 1.4726189120620417\n",
      "Epoch: 218, Iteration: 1/2, Loss: 1.4538520009498503\n",
      "Epoch: 219, Iteration: 1/2, Loss: 1.46577974652872\n",
      "Epoch: 220, Iteration: 1/2, Loss: 1.4575370623402457\n",
      "Epoch: 221, Iteration: 1/2, Loss: 1.452134756370406\n",
      "Epoch: 222, Iteration: 1/2, Loss: 1.4585462097940352\n",
      "Epoch: 223, Iteration: 1/2, Loss: 1.458158724022908\n",
      "Epoch: 224, Iteration: 1/2, Loss: 1.4581316950353713\n",
      "Epoch: 225, Iteration: 1/2, Loss: 1.456664003446192\n",
      "Epoch: 226, Iteration: 1/2, Loss: 1.4496366636456064\n",
      "Epoch: 227, Iteration: 1/2, Loss: 1.4483823003160117\n",
      "Epoch: 228, Iteration: 1/2, Loss: 1.4586282908871584\n",
      "Epoch: 229, Iteration: 1/2, Loss: 1.4470823142868778\n",
      "Epoch: 230, Iteration: 1/2, Loss: 1.4518143612253869\n",
      "Epoch: 231, Iteration: 1/2, Loss: 1.450516764065506\n",
      "Epoch: 232, Iteration: 1/2, Loss: 1.4544768679305753\n",
      "Epoch: 233, Iteration: 1/2, Loss: 1.4466426395926817\n",
      "Epoch: 234, Iteration: 1/2, Loss: 1.448259074950339\n",
      "Epoch: 235, Iteration: 1/2, Loss: 1.443162800135354\n",
      "Epoch: 236, Iteration: 1/2, Loss: 1.4534906010550828\n",
      "Epoch: 237, Iteration: 1/2, Loss: 1.4435166632924654\n",
      "Epoch: 238, Iteration: 1/2, Loss: 1.441891259174649\n",
      "Epoch: 239, Iteration: 1/2, Loss: 1.4452677833373977\n",
      "Epoch: 240, Iteration: 1/2, Loss: 1.4456247963869835\n",
      "Epoch: 241, Iteration: 1/2, Loss: 1.4456156540792626\n",
      "Epoch: 242, Iteration: 1/2, Loss: 1.4404772788246727\n",
      "Epoch: 243, Iteration: 1/2, Loss: 1.447384675543722\n",
      "Epoch: 244, Iteration: 1/2, Loss: 1.4432586267952805\n",
      "Epoch: 245, Iteration: 1/2, Loss: 1.4416335334872405\n",
      "Epoch: 246, Iteration: 1/2, Loss: 1.4409317828296617\n",
      "Epoch: 247, Iteration: 1/2, Loss: 1.4403123661997643\n",
      "Epoch: 248, Iteration: 1/2, Loss: 1.4415873051834385\n",
      "Epoch: 249, Iteration: 1/2, Loss: 1.4371561390689163\n",
      "Epoch: 250, Iteration: 1/2, Loss: 1.4395282022219233\n",
      "Epoch: 251, Iteration: 1/2, Loss: 1.4344747992177727\n",
      "Epoch: 252, Iteration: 1/2, Loss: 1.4426674577144047\n",
      "Epoch: 253, Iteration: 1/2, Loss: 1.4372788629725812\n",
      "Epoch: 254, Iteration: 1/2, Loss: 1.4349162352825808\n",
      "Epoch: 255, Iteration: 1/2, Loss: 1.4368766666399342\n",
      "Epoch: 256, Iteration: 1/2, Loss: 1.4350544150535178\n",
      "Epoch: 257, Iteration: 1/2, Loss: 1.4364748719272433\n",
      "Epoch: 258, Iteration: 1/2, Loss: 1.4330376797128064\n",
      "Epoch: 259, Iteration: 1/2, Loss: 1.4331370746525045\n",
      "Epoch: 260, Iteration: 1/2, Loss: 1.440572783446886\n",
      "Epoch: 261, Iteration: 1/2, Loss: 1.4313787680282553\n",
      "Epoch: 262, Iteration: 1/2, Loss: 1.4322563796712589\n",
      "Epoch: 263, Iteration: 1/2, Loss: 1.4361777690673896\n",
      "Epoch: 264, Iteration: 1/2, Loss: 1.4268962266439797\n",
      "Epoch: 265, Iteration: 1/2, Loss: 1.4367504966424058\n",
      "Epoch: 266, Iteration: 1/2, Loss: 1.4256833700964036\n",
      "Epoch: 267, Iteration: 1/2, Loss: 1.433533653717928\n",
      "Epoch: 268, Iteration: 1/2, Loss: 1.4354013751614405\n",
      "Epoch: 269, Iteration: 1/2, Loss: 1.4238270397154558\n",
      "Epoch: 270, Iteration: 1/2, Loss: 1.4336646562238082\n",
      "Epoch: 271, Iteration: 1/2, Loss: 1.43145911481168\n",
      "Epoch: 272, Iteration: 1/2, Loss: 1.4271968730490119\n",
      "Epoch: 273, Iteration: 1/2, Loss: 1.425996110795913\n",
      "Epoch: 274, Iteration: 1/2, Loss: 1.431267728478348\n",
      "Epoch: 275, Iteration: 1/2, Loss: 1.4295437270003764\n",
      "Epoch: 276, Iteration: 1/2, Loss: 1.4263276852039855\n",
      "Epoch: 277, Iteration: 1/2, Loss: 1.4292235260142183\n",
      "Epoch: 278, Iteration: 1/2, Loss: 1.4256696457393623\n",
      "Epoch: 279, Iteration: 1/2, Loss: 1.428977056435028\n",
      "Epoch: 280, Iteration: 1/2, Loss: 1.4253688138633476\n",
      "Epoch: 281, Iteration: 1/2, Loss: 1.423510422044144\n",
      "Epoch: 282, Iteration: 1/2, Loss: 1.4290807707169049\n",
      "Epoch: 283, Iteration: 1/2, Loss: 1.42449954422248\n",
      "Epoch: 284, Iteration: 1/2, Loss: 1.4234102890439242\n",
      "Epoch: 285, Iteration: 1/2, Loss: 1.4284017555526747\n",
      "Epoch: 286, Iteration: 1/2, Loss: 1.4247701137029787\n",
      "Epoch: 287, Iteration: 1/2, Loss: 1.4259790242913013\n",
      "Epoch: 288, Iteration: 1/2, Loss: 1.4218739024520777\n",
      "Epoch: 289, Iteration: 1/2, Loss: 1.4230092574984727\n",
      "Epoch: 290, Iteration: 1/2, Loss: 1.4261712090737122\n",
      "Epoch: 291, Iteration: 1/2, Loss: 1.4221803161292472\n",
      "Epoch: 292, Iteration: 1/2, Loss: 1.4251009610385563\n",
      "Epoch: 293, Iteration: 1/2, Loss: 1.4195740945182471\n",
      "Epoch: 294, Iteration: 1/2, Loss: 1.420279264797954\n",
      "Epoch: 295, Iteration: 1/2, Loss: 1.4256272441671627\n",
      "Epoch: 296, Iteration: 1/2, Loss: 1.4205631339208407\n",
      "Epoch: 297, Iteration: 1/2, Loss: 1.4226050775790773\n",
      "Epoch: 298, Iteration: 1/2, Loss: 1.4189257283091063\n",
      "Epoch: 299, Iteration: 1/2, Loss: 1.4211412604944134\n",
      "Epoch: 300, Iteration: 1/2, Loss: 1.4223401519937033\n",
      "Epoch: 301, Iteration: 1/2, Loss: 1.4234918753220585\n",
      "Epoch: 302, Iteration: 1/2, Loss: 1.417482902382838\n",
      "Epoch: 303, Iteration: 1/2, Loss: 1.4209591461476045\n",
      "Epoch: 304, Iteration: 1/2, Loss: 1.418581180501083\n",
      "Epoch: 305, Iteration: 1/2, Loss: 1.422948689588536\n",
      "Epoch: 306, Iteration: 1/2, Loss: 1.41771040920518\n",
      "Epoch: 307, Iteration: 1/2, Loss: 1.4192266396088586\n",
      "Epoch: 308, Iteration: 1/2, Loss: 1.4179640959036408\n",
      "Epoch: 309, Iteration: 1/2, Loss: 1.420261947384864\n",
      "Epoch: 310, Iteration: 1/2, Loss: 1.418494303832616\n",
      "Epoch: 311, Iteration: 1/2, Loss: 1.4163557710355712\n",
      "Epoch: 312, Iteration: 1/2, Loss: 1.4190296914351732\n",
      "Epoch: 313, Iteration: 1/2, Loss: 1.4156268964948633\n",
      "Epoch: 314, Iteration: 1/2, Loss: 1.4171355919197928\n",
      "Epoch: 315, Iteration: 1/2, Loss: 1.4183183114505202\n",
      "Epoch: 316, Iteration: 1/2, Loss: 1.4185774142314158\n",
      "Epoch: 317, Iteration: 1/2, Loss: 1.4151934100643504\n",
      "Epoch: 318, Iteration: 1/2, Loss: 1.4197134956889566\n",
      "Epoch: 319, Iteration: 1/2, Loss: 1.4145291285751558\n",
      "Epoch: 320, Iteration: 1/2, Loss: 1.417252955894124\n",
      "Epoch: 321, Iteration: 1/2, Loss: 1.4168182287869011\n",
      "Epoch: 322, Iteration: 1/2, Loss: 1.4155712458922896\n",
      "Epoch: 323, Iteration: 1/2, Loss: 1.4160772322801507\n",
      "Epoch: 324, Iteration: 1/2, Loss: 1.4133425283022554\n",
      "Epoch: 325, Iteration: 1/2, Loss: 1.4181926673013747\n",
      "Epoch: 326, Iteration: 1/2, Loss: 1.4132773666944343\n",
      "Epoch: 327, Iteration: 1/2, Loss: 1.4177622490307296\n",
      "Epoch: 328, Iteration: 1/2, Loss: 1.4148446966427555\n",
      "Epoch: 329, Iteration: 1/2, Loss: 1.4122552316030141\n",
      "Epoch: 330, Iteration: 1/2, Loss: 1.4169892170229779\n",
      "Epoch: 331, Iteration: 1/2, Loss: 1.410750822581489\n",
      "Epoch: 332, Iteration: 1/2, Loss: 1.4145304589540695\n",
      "Epoch: 333, Iteration: 1/2, Loss: 1.4130683740574712\n",
      "Epoch: 334, Iteration: 1/2, Loss: 1.4153876938571908\n",
      "Epoch: 335, Iteration: 1/2, Loss: 1.4141467366922649\n",
      "Epoch: 336, Iteration: 1/2, Loss: 1.4152257083789637\n",
      "Epoch: 337, Iteration: 1/2, Loss: 1.4121080072334138\n",
      "Epoch: 338, Iteration: 1/2, Loss: 1.4128534608880934\n",
      "Epoch: 339, Iteration: 1/2, Loss: 1.4136244135196403\n",
      "Epoch: 340, Iteration: 1/2, Loss: 1.4097916603077774\n",
      "Epoch: 341, Iteration: 1/2, Loss: 1.4144877634260775\n",
      "Epoch: 342, Iteration: 1/2, Loss: 1.4124819501396444\n",
      "Epoch: 343, Iteration: 1/2, Loss: 1.4141754454700595\n",
      "Epoch: 344, Iteration: 1/2, Loss: 1.4092631371266262\n",
      "Epoch: 345, Iteration: 1/2, Loss: 1.4138219874888\n",
      "Epoch: 346, Iteration: 1/2, Loss: 1.4111335878665012\n",
      "Epoch: 347, Iteration: 1/2, Loss: 1.4121885751723582\n",
      "Epoch: 348, Iteration: 1/2, Loss: 1.4130063437222924\n",
      "Epoch: 349, Iteration: 1/2, Loss: 1.4090684055713991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 625/1000 [00:00<00:00, 1464.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350, Iteration: 1/2, Loss: 1.4128907265501447\n",
      "Epoch: 351, Iteration: 1/2, Loss: 1.4103226363343566\n",
      "Epoch: 352, Iteration: 1/2, Loss: 1.4123781092884844\n",
      "Epoch: 353, Iteration: 1/2, Loss: 1.409805099223158\n",
      "Epoch: 354, Iteration: 1/2, Loss: 1.4083160641075643\n",
      "Epoch: 355, Iteration: 1/2, Loss: 1.4128425879585773\n",
      "Epoch: 356, Iteration: 1/2, Loss: 1.408858081863087\n",
      "Epoch: 357, Iteration: 1/2, Loss: 1.4109861907641226\n",
      "Epoch: 358, Iteration: 1/2, Loss: 1.4099409768780422\n",
      "Epoch: 359, Iteration: 1/2, Loss: 1.412227421492957\n",
      "Epoch: 360, Iteration: 1/2, Loss: 1.4093408938518646\n",
      "Epoch: 361, Iteration: 1/2, Loss: 1.409656055298003\n",
      "Epoch: 362, Iteration: 1/2, Loss: 1.409081370111152\n",
      "Epoch: 363, Iteration: 1/2, Loss: 1.410167123526059\n",
      "Epoch: 364, Iteration: 1/2, Loss: 1.408843163099169\n",
      "Epoch: 365, Iteration: 1/2, Loss: 1.4083037781686467\n",
      "Epoch: 366, Iteration: 1/2, Loss: 1.408371925715771\n",
      "Epoch: 367, Iteration: 1/2, Loss: 1.4092378013410274\n",
      "Epoch: 368, Iteration: 1/2, Loss: 1.4094284199706404\n",
      "Epoch: 369, Iteration: 1/2, Loss: 1.4095705630436017\n",
      "Epoch: 370, Iteration: 1/2, Loss: 1.4094868345220999\n",
      "Epoch: 371, Iteration: 1/2, Loss: 1.4085287768510972\n",
      "Epoch: 372, Iteration: 1/2, Loss: 1.4081974520987415\n",
      "Epoch: 373, Iteration: 1/2, Loss: 1.4077721411973254\n",
      "Epoch: 374, Iteration: 1/2, Loss: 1.4071649871003546\n",
      "Epoch: 375, Iteration: 1/2, Loss: 1.4071703456590967\n",
      "Epoch: 376, Iteration: 1/2, Loss: 1.4094424648510122\n",
      "Epoch: 377, Iteration: 1/2, Loss: 1.407730852120272\n",
      "Epoch: 378, Iteration: 1/2, Loss: 1.40722450542239\n",
      "Epoch: 379, Iteration: 1/2, Loss: 1.4081067273290744\n",
      "Epoch: 380, Iteration: 1/2, Loss: 1.4079713349476588\n",
      "Epoch: 381, Iteration: 1/2, Loss: 1.4083524000720384\n",
      "Epoch: 382, Iteration: 1/2, Loss: 1.4055649090845153\n",
      "Epoch: 383, Iteration: 1/2, Loss: 1.4067247657748365\n",
      "Epoch: 384, Iteration: 1/2, Loss: 1.4087703288857893\n",
      "Epoch: 385, Iteration: 1/2, Loss: 1.407427514824056\n",
      "Epoch: 386, Iteration: 1/2, Loss: 1.4054627031641593\n",
      "Epoch: 387, Iteration: 1/2, Loss: 1.4068447963644168\n",
      "Epoch: 388, Iteration: 1/2, Loss: 1.4066571097076894\n",
      "Epoch: 389, Iteration: 1/2, Loss: 1.4051827256015215\n",
      "Epoch: 390, Iteration: 1/2, Loss: 1.4081117168108377\n",
      "Epoch: 391, Iteration: 1/2, Loss: 1.4074703308304384\n",
      "Epoch: 392, Iteration: 1/2, Loss: 1.4046290086799158\n",
      "Epoch: 393, Iteration: 1/2, Loss: 1.4056148277106288\n",
      "Epoch: 394, Iteration: 1/2, Loss: 1.4057561383956432\n",
      "Epoch: 395, Iteration: 1/2, Loss: 1.4074085945551782\n",
      "Epoch: 396, Iteration: 1/2, Loss: 1.406871301770299\n",
      "Epoch: 397, Iteration: 1/2, Loss: 1.4051231893430973\n",
      "Epoch: 398, Iteration: 1/2, Loss: 1.4049107721830598\n",
      "Epoch: 399, Iteration: 1/2, Loss: 1.4042550328347938\n",
      "Epoch: 400, Iteration: 1/2, Loss: 1.4069078935163446\n",
      "Epoch: 401, Iteration: 1/2, Loss: 1.4066118870427304\n",
      "Epoch: 402, Iteration: 1/2, Loss: 1.4040430407219961\n",
      "Epoch: 403, Iteration: 1/2, Loss: 1.4039173251823867\n",
      "Epoch: 404, Iteration: 1/2, Loss: 1.4069618441360376\n",
      "Epoch: 405, Iteration: 1/2, Loss: 1.404091136143843\n",
      "Epoch: 406, Iteration: 1/2, Loss: 1.4051359252401086\n",
      "Epoch: 407, Iteration: 1/2, Loss: 1.4051470232039274\n",
      "Epoch: 408, Iteration: 1/2, Loss: 1.4044619960681546\n",
      "Epoch: 409, Iteration: 1/2, Loss: 1.4053490408282663\n",
      "Epoch: 410, Iteration: 1/2, Loss: 1.404027198062387\n",
      "Epoch: 411, Iteration: 1/2, Loss: 1.4036571061944032\n",
      "Epoch: 412, Iteration: 1/2, Loss: 1.4069111212976995\n",
      "Epoch: 413, Iteration: 1/2, Loss: 1.4024198634404605\n",
      "Epoch: 414, Iteration: 1/2, Loss: 1.405898942226449\n",
      "Epoch: 415, Iteration: 1/2, Loss: 1.4042039270564093\n",
      "Epoch: 416, Iteration: 1/2, Loss: 1.4043219814596903\n",
      "Epoch: 417, Iteration: 1/2, Loss: 1.4035483547280627\n",
      "Epoch: 418, Iteration: 1/2, Loss: 1.4037536694210597\n",
      "Epoch: 419, Iteration: 1/2, Loss: 1.404363306583457\n",
      "Epoch: 420, Iteration: 1/2, Loss: 1.4039991861767103\n",
      "Epoch: 421, Iteration: 1/2, Loss: 1.4022744408258685\n",
      "Epoch: 422, Iteration: 1/2, Loss: 1.404414333959767\n",
      "Epoch: 423, Iteration: 1/2, Loss: 1.404234352398028\n",
      "Epoch: 424, Iteration: 1/2, Loss: 1.403020561177906\n",
      "Epoch: 425, Iteration: 1/2, Loss: 1.4015794246442739\n",
      "Epoch: 426, Iteration: 1/2, Loss: 1.4056440908245085\n",
      "Epoch: 427, Iteration: 1/2, Loss: 1.4024586873245608\n",
      "Epoch: 428, Iteration: 1/2, Loss: 1.4029025698610107\n",
      "Epoch: 429, Iteration: 1/2, Loss: 1.4031232817556054\n",
      "Epoch: 430, Iteration: 1/2, Loss: 1.4034967111961172\n",
      "Epoch: 431, Iteration: 1/2, Loss: 1.4029757494768516\n",
      "Epoch: 432, Iteration: 1/2, Loss: 1.4020533201696161\n",
      "Epoch: 433, Iteration: 1/2, Loss: 1.4029881298679436\n",
      "Epoch: 434, Iteration: 1/2, Loss: 1.40216774678783\n",
      "Epoch: 435, Iteration: 1/2, Loss: 1.4027027878747234\n",
      "Epoch: 436, Iteration: 1/2, Loss: 1.4027817796694104\n",
      "Epoch: 437, Iteration: 1/2, Loss: 1.4030085538837058\n",
      "Epoch: 438, Iteration: 1/2, Loss: 1.403018562883001\n",
      "Epoch: 439, Iteration: 1/2, Loss: 1.4018971590666796\n",
      "Epoch: 440, Iteration: 1/2, Loss: 1.401492237018236\n",
      "Epoch: 441, Iteration: 1/2, Loss: 1.4044255288170766\n",
      "Epoch: 442, Iteration: 1/2, Loss: 1.4010587048553487\n",
      "Epoch: 443, Iteration: 1/2, Loss: 1.4017326273522255\n",
      "Epoch: 444, Iteration: 1/2, Loss: 1.4023956974761433\n",
      "Epoch: 445, Iteration: 1/2, Loss: 1.4022649692691938\n",
      "Epoch: 446, Iteration: 1/2, Loss: 1.402532820370981\n",
      "Epoch: 447, Iteration: 1/2, Loss: 1.400346415339\n",
      "Epoch: 448, Iteration: 1/2, Loss: 1.40183641851172\n",
      "Epoch: 449, Iteration: 1/2, Loss: 1.401773051790284\n",
      "Epoch: 450, Iteration: 1/2, Loss: 1.4029620723290346\n",
      "Epoch: 451, Iteration: 1/2, Loss: 1.4008069872796478\n",
      "Epoch: 452, Iteration: 1/2, Loss: 1.4021361084016348\n",
      "Epoch: 453, Iteration: 1/2, Loss: 1.4004398354029113\n",
      "Epoch: 454, Iteration: 1/2, Loss: 1.4034737849298615\n",
      "Epoch: 455, Iteration: 1/2, Loss: 1.3997886400418824\n",
      "Epoch: 456, Iteration: 1/2, Loss: 1.401343015195156\n",
      "Epoch: 457, Iteration: 1/2, Loss: 1.4020735584324453\n",
      "Epoch: 458, Iteration: 1/2, Loss: 1.4020122897804437\n",
      "Epoch: 459, Iteration: 1/2, Loss: 1.4004683439944718\n",
      "Epoch: 460, Iteration: 1/2, Loss: 1.400615046766098\n",
      "Epoch: 461, Iteration: 1/2, Loss: 1.4010455270843067\n",
      "Epoch: 462, Iteration: 1/2, Loss: 1.400855289366857\n",
      "Epoch: 463, Iteration: 1/2, Loss: 1.4002771721181309\n",
      "Epoch: 464, Iteration: 1/2, Loss: 1.4016264986561573\n",
      "Epoch: 465, Iteration: 1/2, Loss: 1.4000623714637226\n",
      "Epoch: 466, Iteration: 1/2, Loss: 1.4017591628958448\n",
      "Epoch: 467, Iteration: 1/2, Loss: 1.4010761374018474\n",
      "Epoch: 468, Iteration: 1/2, Loss: 1.4005147935603124\n",
      "Epoch: 469, Iteration: 1/2, Loss: 1.3997317382499515\n",
      "Epoch: 470, Iteration: 1/2, Loss: 1.401419646052638\n",
      "Epoch: 471, Iteration: 1/2, Loss: 1.3994753756086102\n",
      "Epoch: 472, Iteration: 1/2, Loss: 1.4010471489682994\n",
      "Epoch: 473, Iteration: 1/2, Loss: 1.4000072121616087\n",
      "Epoch: 474, Iteration: 1/2, Loss: 1.4005799300319999\n",
      "Epoch: 475, Iteration: 1/2, Loss: 1.4011090973123905\n",
      "Epoch: 476, Iteration: 1/2, Loss: 1.3987463974302607\n",
      "Epoch: 477, Iteration: 1/2, Loss: 1.4017566878918184\n",
      "Epoch: 478, Iteration: 1/2, Loss: 1.3987821011174033\n",
      "Epoch: 479, Iteration: 1/2, Loss: 1.4006712410615068\n",
      "Epoch: 480, Iteration: 1/2, Loss: 1.4002462170198302\n",
      "Epoch: 481, Iteration: 1/2, Loss: 1.3994648398697946\n",
      "Epoch: 482, Iteration: 1/2, Loss: 1.399923205803996\n",
      "Epoch: 483, Iteration: 1/2, Loss: 1.4003062570279305\n",
      "Epoch: 484, Iteration: 1/2, Loss: 1.3993455226063558\n",
      "Epoch: 485, Iteration: 1/2, Loss: 1.3997551434556779\n",
      "Epoch: 486, Iteration: 1/2, Loss: 1.4002857519361231\n",
      "Epoch: 487, Iteration: 1/2, Loss: 1.3991989759870334\n",
      "Epoch: 488, Iteration: 1/2, Loss: 1.4005477858819075\n",
      "Epoch: 489, Iteration: 1/2, Loss: 1.398860996606504\n",
      "Epoch: 490, Iteration: 1/2, Loss: 1.3995131021044496\n",
      "Epoch: 491, Iteration: 1/2, Loss: 1.399352069362497\n",
      "Epoch: 492, Iteration: 1/2, Loss: 1.3986062063356366\n",
      "Epoch: 493, Iteration: 1/2, Loss: 1.4002968543261254\n",
      "Epoch: 494, Iteration: 1/2, Loss: 1.3987592453311737\n",
      "Epoch: 495, Iteration: 1/2, Loss: 1.4004067962509787\n",
      "Epoch: 496, Iteration: 1/2, Loss: 1.3979905616266006\n",
      "Epoch: 497, Iteration: 1/2, Loss: 1.3999674403447306\n",
      "Epoch: 498, Iteration: 1/2, Loss: 1.398488247294313\n",
      "Epoch: 499, Iteration: 1/2, Loss: 1.3997473952936041\n",
      "Epoch: 500, Iteration: 1/2, Loss: 1.399165768721165\n",
      "Epoch: 501, Iteration: 1/2, Loss: 1.3985690837837659\n",
      "Epoch: 502, Iteration: 1/2, Loss: 1.3988487951677193\n",
      "Epoch: 503, Iteration: 1/2, Loss: 1.3991376745980058\n",
      "Epoch: 504, Iteration: 1/2, Loss: 1.3994193338852186\n",
      "Epoch: 505, Iteration: 1/2, Loss: 1.3986051239894144\n",
      "Epoch: 506, Iteration: 1/2, Loss: 1.398357966483375\n",
      "Epoch: 507, Iteration: 1/2, Loss: 1.3996100688624946\n",
      "Epoch: 508, Iteration: 1/2, Loss: 1.398365061558272\n",
      "Epoch: 509, Iteration: 1/2, Loss: 1.398987101179194\n",
      "Epoch: 510, Iteration: 1/2, Loss: 1.3979681234757209\n",
      "Epoch: 511, Iteration: 1/2, Loss: 1.398261090463538\n",
      "Epoch: 512, Iteration: 1/2, Loss: 1.3994841390578059\n",
      "Epoch: 513, Iteration: 1/2, Loss: 1.397956614386858\n",
      "Epoch: 514, Iteration: 1/2, Loss: 1.397395336227861\n",
      "Epoch: 515, Iteration: 1/2, Loss: 1.3989388402579963\n",
      "Epoch: 516, Iteration: 1/2, Loss: 1.3988829493103263\n",
      "Epoch: 517, Iteration: 1/2, Loss: 1.397589571283465\n",
      "Epoch: 518, Iteration: 1/2, Loss: 1.3993334372122432\n",
      "Epoch: 519, Iteration: 1/2, Loss: 1.3972055510927381\n",
      "Epoch: 520, Iteration: 1/2, Loss: 1.3992472608931825\n",
      "Epoch: 521, Iteration: 1/2, Loss: 1.3970277878276853\n",
      "Epoch: 522, Iteration: 1/2, Loss: 1.398747521120792\n",
      "Epoch: 523, Iteration: 1/2, Loss: 1.3982849105022384\n",
      "Epoch: 524, Iteration: 1/2, Loss: 1.3986625972671813\n",
      "Epoch: 525, Iteration: 1/2, Loss: 1.397300447776637\n",
      "Epoch: 526, Iteration: 1/2, Loss: 1.398065987306698\n",
      "Epoch: 527, Iteration: 1/2, Loss: 1.3985398040998953\n",
      "Epoch: 528, Iteration: 1/2, Loss: 1.3968942335687795\n",
      "Epoch: 529, Iteration: 1/2, Loss: 1.39754987874384\n",
      "Epoch: 530, Iteration: 1/2, Loss: 1.398328194769256\n",
      "Epoch: 531, Iteration: 1/2, Loss: 1.3985673956978164\n",
      "Epoch: 532, Iteration: 1/2, Loss: 1.3963554521158767\n",
      "Epoch: 533, Iteration: 1/2, Loss: 1.3983124804791771\n",
      "Epoch: 534, Iteration: 1/2, Loss: 1.3982612551917477\n",
      "Epoch: 535, Iteration: 1/2, Loss: 1.3971343422381053\n",
      "Epoch: 536, Iteration: 1/2, Loss: 1.397695471177899\n",
      "Epoch: 537, Iteration: 1/2, Loss: 1.397271109053438\n",
      "Epoch: 538, Iteration: 1/2, Loss: 1.397129159317993\n",
      "Epoch: 539, Iteration: 1/2, Loss: 1.3979850057308907\n",
      "Epoch: 540, Iteration: 1/2, Loss: 1.3972614857735053\n",
      "Epoch: 541, Iteration: 1/2, Loss: 1.3976118911655424\n",
      "Epoch: 542, Iteration: 1/2, Loss: 1.3973718125352124\n",
      "Epoch: 543, Iteration: 1/2, Loss: 1.3967744068263668\n",
      "Epoch: 544, Iteration: 1/2, Loss: 1.3979844502046301\n",
      "Epoch: 545, Iteration: 1/2, Loss: 1.3974670688626736\n",
      "Epoch: 546, Iteration: 1/2, Loss: 1.3974407892679968\n",
      "Epoch: 547, Iteration: 1/2, Loss: 1.3961641828522706\n",
      "Epoch: 548, Iteration: 1/2, Loss: 1.398401957011267\n",
      "Epoch: 549, Iteration: 1/2, Loss: 1.3964964492387435\n",
      "Epoch: 550, Iteration: 1/2, Loss: 1.3973785881509588\n",
      "Epoch: 551, Iteration: 1/2, Loss: 1.3964406744173705\n",
      "Epoch: 552, Iteration: 1/2, Loss: 1.397672361252838\n",
      "Epoch: 553, Iteration: 1/2, Loss: 1.3970879756002454\n",
      "Epoch: 554, Iteration: 1/2, Loss: 1.3963464310258744\n",
      "Epoch: 555, Iteration: 1/2, Loss: 1.397487228263589\n",
      "Epoch: 556, Iteration: 1/2, Loss: 1.3963664862451641\n",
      "Epoch: 557, Iteration: 1/2, Loss: 1.39749828829753\n",
      "Epoch: 558, Iteration: 1/2, Loss: 1.397125685403152\n",
      "Epoch: 559, Iteration: 1/2, Loss: 1.3963609966653547\n",
      "Epoch: 560, Iteration: 1/2, Loss: 1.3964297611974448\n",
      "Epoch: 561, Iteration: 1/2, Loss: 1.3967521071428757\n",
      "Epoch: 562, Iteration: 1/2, Loss: 1.3975154467542759\n",
      "Epoch: 563, Iteration: 1/2, Loss: 1.3957240320713025\n",
      "Epoch: 564, Iteration: 1/2, Loss: 1.396989423268451\n",
      "Epoch: 565, Iteration: 1/2, Loss: 1.396971910006206\n",
      "Epoch: 566, Iteration: 1/2, Loss: 1.395914153226434\n",
      "Epoch: 567, Iteration: 1/2, Loss: 1.3975129130442323\n",
      "Epoch: 568, Iteration: 1/2, Loss: 1.3954761354093679\n",
      "Epoch: 569, Iteration: 1/2, Loss: 1.3969583092351265\n",
      "Epoch: 570, Iteration: 1/2, Loss: 1.3970701601822757\n",
      "Epoch: 571, Iteration: 1/2, Loss: 1.3955790991138284\n",
      "Epoch: 572, Iteration: 1/2, Loss: 1.396229853541285\n",
      "Epoch: 573, Iteration: 1/2, Loss: 1.3971556441931567\n",
      "Epoch: 574, Iteration: 1/2, Loss: 1.3958532802514945\n",
      "Epoch: 575, Iteration: 1/2, Loss: 1.3963212897266088\n",
      "Epoch: 576, Iteration: 1/2, Loss: 1.3966327545823216\n",
      "Epoch: 577, Iteration: 1/2, Loss: 1.3958437174575518\n",
      "Epoch: 578, Iteration: 1/2, Loss: 1.3970804962087784\n",
      "Epoch: 579, Iteration: 1/2, Loss: 1.3956097925878062\n",
      "Epoch: 580, Iteration: 1/2, Loss: 1.396617597269279\n",
      "Epoch: 581, Iteration: 1/2, Loss: 1.395800806640708\n",
      "Epoch: 582, Iteration: 1/2, Loss: 1.3958764076083274\n",
      "Epoch: 583, Iteration: 1/2, Loss: 1.3958336394012947\n",
      "Epoch: 584, Iteration: 1/2, Loss: 1.3968119991621806\n",
      "Epoch: 585, Iteration: 1/2, Loss: 1.395556335950876\n",
      "Epoch: 586, Iteration: 1/2, Loss: 1.3956631201675713\n",
      "Epoch: 587, Iteration: 1/2, Loss: 1.397149682422342\n",
      "Epoch: 588, Iteration: 1/2, Loss: 1.3953061410979988\n",
      "Epoch: 589, Iteration: 1/2, Loss: 1.3957536448825412\n",
      "Epoch: 590, Iteration: 1/2, Loss: 1.395904976840646\n",
      "Epoch: 591, Iteration: 1/2, Loss: 1.3961056178485072\n",
      "Epoch: 592, Iteration: 1/2, Loss: 1.3960137980405103\n",
      "Epoch: 593, Iteration: 1/2, Loss: 1.3954167949153995\n",
      "Epoch: 594, Iteration: 1/2, Loss: 1.395704895956055\n",
      "Epoch: 595, Iteration: 1/2, Loss: 1.3958515854465898\n",
      "Epoch: 596, Iteration: 1/2, Loss: 1.3963867411896118\n",
      "Epoch: 597, Iteration: 1/2, Loss: 1.3954626686353833\n",
      "Epoch: 598, Iteration: 1/2, Loss: 1.394891981369705\n",
      "Epoch: 599, Iteration: 1/2, Loss: 1.3968508492446086\n",
      "Epoch: 600, Iteration: 1/2, Loss: 1.3947591369534535\n",
      "Epoch: 601, Iteration: 1/2, Loss: 1.395361120847463\n",
      "Epoch: 602, Iteration: 1/2, Loss: 1.3955243701414402\n",
      "Epoch: 603, Iteration: 1/2, Loss: 1.3956209517069604\n",
      "Epoch: 604, Iteration: 1/2, Loss: 1.3960276779093639\n",
      "Epoch: 605, Iteration: 1/2, Loss: 1.395896414460251\n",
      "Epoch: 606, Iteration: 1/2, Loss: 1.395482733266305\n",
      "Epoch: 607, Iteration: 1/2, Loss: 1.3949862239728477\n",
      "Epoch: 608, Iteration: 1/2, Loss: 1.3954904601072278\n",
      "Epoch: 609, Iteration: 1/2, Loss: 1.39540637278588\n",
      "Epoch: 610, Iteration: 1/2, Loss: 1.3956843541637272\n",
      "Epoch: 611, Iteration: 1/2, Loss: 1.395075904791089\n",
      "Epoch: 612, Iteration: 1/2, Loss: 1.3954748857822876\n",
      "Epoch: 613, Iteration: 1/2, Loss: 1.3957678213724882\n",
      "Epoch: 614, Iteration: 1/2, Loss: 1.3948264369733532\n",
      "Epoch: 615, Iteration: 1/2, Loss: 1.3945827534915716\n",
      "Epoch: 616, Iteration: 1/2, Loss: 1.3961513059775736\n",
      "Epoch: 617, Iteration: 1/2, Loss: 1.39421922931752\n",
      "Epoch: 618, Iteration: 1/2, Loss: 1.3955660805933752\n",
      "Epoch: 619, Iteration: 1/2, Loss: 1.3952414537107733\n",
      "Epoch: 620, Iteration: 1/2, Loss: 1.394831009419756\n",
      "Epoch: 621, Iteration: 1/2, Loss: 1.3951202608741782\n",
      "Epoch: 622, Iteration: 1/2, Loss: 1.3951726710165406\n",
      "Epoch: 623, Iteration: 1/2, Loss: 1.3954433521278258\n",
      "Epoch: 624, Iteration: 1/2, Loss: 1.3949114037707275\n",
      "Epoch: 625, Iteration: 1/2, Loss: 1.3953163392574353\n",
      "Epoch: 626, Iteration: 1/2, Loss: 1.3945820125688935\n",
      "Epoch: 627, Iteration: 1/2, Loss: 1.3958426630030858\n",
      "Epoch: 628, Iteration: 1/2, Loss: 1.3948220689813593\n",
      "Epoch: 629, Iteration: 1/2, Loss: 1.3947050793757696\n",
      "Epoch: 630, Iteration: 1/2, Loss: 1.395273028604714\n",
      "Epoch: 631, Iteration: 1/2, Loss: 1.394681011188308\n",
      "Epoch: 632, Iteration: 1/2, Loss: 1.3947141510851282\n",
      "Epoch: 633, Iteration: 1/2, Loss: 1.3942510795078809\n",
      "Epoch: 634, Iteration: 1/2, Loss: 1.3947515216373545\n",
      "Epoch: 635, Iteration: 1/2, Loss: 1.395259960677727\n",
      "Epoch: 636, Iteration: 1/2, Loss: 1.394751682244943\n",
      "Epoch: 637, Iteration: 1/2, Loss: 1.3942783842272624\n",
      "Epoch: 638, Iteration: 1/2, Loss: 1.3952913003905922\n",
      "Epoch: 639, Iteration: 1/2, Loss: 1.3945139705837697\n",
      "Epoch: 640, Iteration: 1/2, Loss: 1.3943394704754295\n",
      "Epoch: 641, Iteration: 1/2, Loss: 1.3948947544158798\n",
      "Epoch: 642, Iteration: 1/2, Loss: 1.3949758453783891\n",
      "Epoch: 643, Iteration: 1/2, Loss: 1.3945518019830347\n",
      "Epoch: 644, Iteration: 1/2, Loss: 1.3948336470017213\n",
      "Epoch: 645, Iteration: 1/2, Loss: 1.394311041791868\n",
      "Epoch: 646, Iteration: 1/2, Loss: 1.3943667460243756\n",
      "Epoch: 647, Iteration: 1/2, Loss: 1.394247166073324\n",
      "Epoch: 648, Iteration: 1/2, Loss: 1.39521388528104\n",
      "Epoch: 649, Iteration: 1/2, Loss: 1.3944311555594906\n",
      "Epoch: 650, Iteration: 1/2, Loss: 1.3940649170082862\n",
      "Epoch: 651, Iteration: 1/2, Loss: 1.3952454872495748\n",
      "Epoch: 652, Iteration: 1/2, Loss: 1.3936632325652216\n",
      "Epoch: 653, Iteration: 1/2, Loss: 1.3951313799708145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1666.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 654, Iteration: 1/2, Loss: 1.3942576496718835\n",
      "Epoch: 655, Iteration: 1/2, Loss: 1.394426481108199\n",
      "Epoch: 656, Iteration: 1/2, Loss: 1.393640906614933\n",
      "Epoch: 657, Iteration: 1/2, Loss: 1.395015255710276\n",
      "Epoch: 658, Iteration: 1/2, Loss: 1.3939862918437202\n",
      "Epoch: 659, Iteration: 1/2, Loss: 1.3946354290347847\n",
      "Epoch: 660, Iteration: 1/2, Loss: 1.3945370183600487\n",
      "Epoch: 661, Iteration: 1/2, Loss: 1.3940522307980654\n",
      "Epoch: 662, Iteration: 1/2, Loss: 1.393534599323104\n",
      "Epoch: 663, Iteration: 1/2, Loss: 1.3944796428857247\n",
      "Epoch: 664, Iteration: 1/2, Loss: 1.3944225052702461\n",
      "Epoch: 665, Iteration: 1/2, Loss: 1.3944171525139901\n",
      "Epoch: 666, Iteration: 1/2, Loss: 1.3943730835176429\n",
      "Epoch: 667, Iteration: 1/2, Loss: 1.3932417265384984\n",
      "Epoch: 668, Iteration: 1/2, Loss: 1.3947064452945992\n",
      "Epoch: 669, Iteration: 1/2, Loss: 1.3940411831772115\n",
      "Epoch: 670, Iteration: 1/2, Loss: 1.3939753458287356\n",
      "Epoch: 671, Iteration: 1/2, Loss: 1.3944675348214775\n",
      "Epoch: 672, Iteration: 1/2, Loss: 1.3939577537337033\n",
      "Epoch: 673, Iteration: 1/2, Loss: 1.394195709289123\n",
      "Epoch: 674, Iteration: 1/2, Loss: 1.393670774161795\n",
      "Epoch: 675, Iteration: 1/2, Loss: 1.3939260069117494\n",
      "Epoch: 676, Iteration: 1/2, Loss: 1.3937968862324164\n",
      "Epoch: 677, Iteration: 1/2, Loss: 1.3940271473212154\n",
      "Epoch: 678, Iteration: 1/2, Loss: 1.3936353485588593\n",
      "Epoch: 679, Iteration: 1/2, Loss: 1.3941285574733855\n",
      "Epoch: 680, Iteration: 1/2, Loss: 1.3944740030594835\n",
      "Epoch: 681, Iteration: 1/2, Loss: 1.3931631566173053\n",
      "Epoch: 682, Iteration: 1/2, Loss: 1.3939379346068974\n",
      "Epoch: 683, Iteration: 1/2, Loss: 1.3936764511409945\n",
      "Epoch: 684, Iteration: 1/2, Loss: 1.393911901166692\n",
      "Epoch: 685, Iteration: 1/2, Loss: 1.3938590585475863\n",
      "Epoch: 686, Iteration: 1/2, Loss: 1.3940002406091496\n",
      "Epoch: 687, Iteration: 1/2, Loss: 1.393960184190222\n",
      "Epoch: 688, Iteration: 1/2, Loss: 1.3936527385551\n",
      "Epoch: 689, Iteration: 1/2, Loss: 1.3940040457623026\n",
      "Epoch: 690, Iteration: 1/2, Loss: 1.393374755072653\n",
      "Epoch: 691, Iteration: 1/2, Loss: 1.393926833914225\n",
      "Epoch: 692, Iteration: 1/2, Loss: 1.3936964447228553\n",
      "Epoch: 693, Iteration: 1/2, Loss: 1.393198737824163\n",
      "Epoch: 694, Iteration: 1/2, Loss: 1.3937374596164396\n",
      "Epoch: 695, Iteration: 1/2, Loss: 1.3937475557357\n",
      "Epoch: 696, Iteration: 1/2, Loss: 1.393630563748058\n",
      "Epoch: 697, Iteration: 1/2, Loss: 1.3940571927090137\n",
      "Epoch: 698, Iteration: 1/2, Loss: 1.393887312027359\n",
      "Epoch: 699, Iteration: 1/2, Loss: 1.393177951318255\n",
      "Epoch: 700, Iteration: 1/2, Loss: 1.3934940642150804\n",
      "Epoch: 701, Iteration: 1/2, Loss: 1.3939748781600216\n",
      "Epoch: 702, Iteration: 1/2, Loss: 1.3927394489774862\n",
      "Epoch: 703, Iteration: 1/2, Loss: 1.3943018198370438\n",
      "Epoch: 704, Iteration: 1/2, Loss: 1.3927104922127849\n",
      "Epoch: 705, Iteration: 1/2, Loss: 1.3937782396945528\n",
      "Epoch: 706, Iteration: 1/2, Loss: 1.393095088380281\n",
      "Epoch: 707, Iteration: 1/2, Loss: 1.3937096924553587\n",
      "Epoch: 708, Iteration: 1/2, Loss: 1.3941278386710136\n",
      "Epoch: 709, Iteration: 1/2, Loss: 1.393248284926488\n",
      "Epoch: 710, Iteration: 1/2, Loss: 1.3926861616836015\n",
      "Epoch: 711, Iteration: 1/2, Loss: 1.3938996888566928\n",
      "Epoch: 712, Iteration: 1/2, Loss: 1.3932723677704169\n",
      "Epoch: 713, Iteration: 1/2, Loss: 1.393737149640372\n",
      "Epoch: 714, Iteration: 1/2, Loss: 1.392535379472865\n",
      "Epoch: 715, Iteration: 1/2, Loss: 1.3933559994296583\n",
      "Epoch: 716, Iteration: 1/2, Loss: 1.3932026281697745\n",
      "Epoch: 717, Iteration: 1/2, Loss: 1.3938091740371878\n",
      "Epoch: 718, Iteration: 1/2, Loss: 1.393404136791655\n",
      "Epoch: 719, Iteration: 1/2, Loss: 1.3933825537063778\n",
      "Epoch: 720, Iteration: 1/2, Loss: 1.3929582314523308\n",
      "Epoch: 721, Iteration: 1/2, Loss: 1.393390611993211\n",
      "Epoch: 722, Iteration: 1/2, Loss: 1.3932127631800624\n",
      "Epoch: 723, Iteration: 1/2, Loss: 1.3931267754187509\n",
      "Epoch: 724, Iteration: 1/2, Loss: 1.3928970130981337\n",
      "Epoch: 725, Iteration: 1/2, Loss: 1.3928856765123245\n",
      "Epoch: 726, Iteration: 1/2, Loss: 1.3937313735874222\n",
      "Epoch: 727, Iteration: 1/2, Loss: 1.3925630422262452\n",
      "Epoch: 728, Iteration: 1/2, Loss: 1.3934638340030174\n",
      "Epoch: 729, Iteration: 1/2, Loss: 1.3931209301270497\n",
      "Epoch: 730, Iteration: 1/2, Loss: 1.3929928179669342\n",
      "Epoch: 731, Iteration: 1/2, Loss: 1.3931793551688179\n",
      "Epoch: 732, Iteration: 1/2, Loss: 1.3928746776433836\n",
      "Epoch: 733, Iteration: 1/2, Loss: 1.3932292218033604\n",
      "Epoch: 734, Iteration: 1/2, Loss: 1.393445566185782\n",
      "Epoch: 735, Iteration: 1/2, Loss: 1.392436087092166\n",
      "Epoch: 736, Iteration: 1/2, Loss: 1.3934160070859942\n",
      "Epoch: 737, Iteration: 1/2, Loss: 1.39242977443641\n",
      "Epoch: 738, Iteration: 1/2, Loss: 1.3933107446685342\n",
      "Epoch: 739, Iteration: 1/2, Loss: 1.39325138313747\n",
      "Epoch: 740, Iteration: 1/2, Loss: 1.3931536069346415\n",
      "Epoch: 741, Iteration: 1/2, Loss: 1.3925435814859388\n",
      "Epoch: 742, Iteration: 1/2, Loss: 1.3929839237356547\n",
      "Epoch: 743, Iteration: 1/2, Loss: 1.3925733835752339\n",
      "Epoch: 744, Iteration: 1/2, Loss: 1.3928389418336922\n",
      "Epoch: 745, Iteration: 1/2, Loss: 1.3936630175909253\n",
      "Epoch: 746, Iteration: 1/2, Loss: 1.3925404599696747\n",
      "Epoch: 747, Iteration: 1/2, Loss: 1.3925697089503588\n",
      "Epoch: 748, Iteration: 1/2, Loss: 1.393120180149196\n",
      "Epoch: 749, Iteration: 1/2, Loss: 1.3923720984191066\n",
      "Epoch: 750, Iteration: 1/2, Loss: 1.393106210404926\n",
      "Epoch: 751, Iteration: 1/2, Loss: 1.3932085701009453\n",
      "Epoch: 752, Iteration: 1/2, Loss: 1.392373056775729\n",
      "Epoch: 753, Iteration: 1/2, Loss: 1.3928592747268225\n",
      "Epoch: 754, Iteration: 1/2, Loss: 1.3923757665228522\n",
      "Epoch: 755, Iteration: 1/2, Loss: 1.392914055861315\n",
      "Epoch: 756, Iteration: 1/2, Loss: 1.3933249446036526\n",
      "Epoch: 757, Iteration: 1/2, Loss: 1.3923325931662052\n",
      "Epoch: 758, Iteration: 1/2, Loss: 1.3927698467528178\n",
      "Epoch: 759, Iteration: 1/2, Loss: 1.3927720839161295\n",
      "Epoch: 760, Iteration: 1/2, Loss: 1.3926491248745314\n",
      "Epoch: 761, Iteration: 1/2, Loss: 1.3923887874603873\n",
      "Epoch: 762, Iteration: 1/2, Loss: 1.3930385744902278\n",
      "Epoch: 763, Iteration: 1/2, Loss: 1.392005639979268\n",
      "Epoch: 764, Iteration: 1/2, Loss: 1.392872429507006\n",
      "Epoch: 765, Iteration: 1/2, Loss: 1.3928312177648703\n",
      "Epoch: 766, Iteration: 1/2, Loss: 1.392599818772367\n",
      "Epoch: 767, Iteration: 1/2, Loss: 1.3928053035339074\n",
      "Epoch: 768, Iteration: 1/2, Loss: 1.3923557355273197\n",
      "Epoch: 769, Iteration: 1/2, Loss: 1.392470052112342\n",
      "Epoch: 770, Iteration: 1/2, Loss: 1.3925732675932756\n",
      "Epoch: 771, Iteration: 1/2, Loss: 1.3928429052254958\n",
      "Epoch: 772, Iteration: 1/2, Loss: 1.392216056223471\n",
      "Epoch: 773, Iteration: 1/2, Loss: 1.3925628764987825\n",
      "Epoch: 774, Iteration: 1/2, Loss: 1.3925096966388455\n",
      "Epoch: 775, Iteration: 1/2, Loss: 1.3927007684767645\n",
      "Epoch: 776, Iteration: 1/2, Loss: 1.3919676879661453\n",
      "Epoch: 777, Iteration: 1/2, Loss: 1.3927386970070308\n",
      "Epoch: 778, Iteration: 1/2, Loss: 1.3921948024714608\n",
      "Epoch: 779, Iteration: 1/2, Loss: 1.3922752653326174\n",
      "Epoch: 780, Iteration: 1/2, Loss: 1.3927613492595357\n",
      "Epoch: 781, Iteration: 1/2, Loss: 1.3925525374412837\n",
      "Epoch: 782, Iteration: 1/2, Loss: 1.3919236603990648\n",
      "Epoch: 783, Iteration: 1/2, Loss: 1.3928870572092524\n",
      "Epoch: 784, Iteration: 1/2, Loss: 1.3920883829425486\n",
      "Epoch: 785, Iteration: 1/2, Loss: 1.392785124100448\n",
      "Epoch: 786, Iteration: 1/2, Loss: 1.392128927081989\n",
      "Epoch: 787, Iteration: 1/2, Loss: 1.3920905931808851\n",
      "Epoch: 788, Iteration: 1/2, Loss: 1.3925880041539356\n",
      "Epoch: 789, Iteration: 1/2, Loss: 1.3925252589195076\n",
      "Epoch: 790, Iteration: 1/2, Loss: 1.3920957525402493\n",
      "Epoch: 791, Iteration: 1/2, Loss: 1.3920106468816902\n",
      "Epoch: 792, Iteration: 1/2, Loss: 1.392303202158209\n",
      "Epoch: 793, Iteration: 1/2, Loss: 1.3925141700898804\n",
      "Epoch: 794, Iteration: 1/2, Loss: 1.3920625489952063\n",
      "Epoch: 795, Iteration: 1/2, Loss: 1.3926084598776043\n",
      "Epoch: 796, Iteration: 1/2, Loss: 1.3918003336908131\n",
      "Epoch: 797, Iteration: 1/2, Loss: 1.392295017977665\n",
      "Epoch: 798, Iteration: 1/2, Loss: 1.3923317054408497\n",
      "Epoch: 799, Iteration: 1/2, Loss: 1.3924393900173555\n",
      "Epoch: 800, Iteration: 1/2, Loss: 1.3919713791661947\n",
      "Epoch: 801, Iteration: 1/2, Loss: 1.3918094827018188\n",
      "Epoch: 802, Iteration: 1/2, Loss: 1.3927494453992648\n",
      "Epoch: 803, Iteration: 1/2, Loss: 1.3915104785546752\n",
      "Epoch: 804, Iteration: 1/2, Loss: 1.3923599394574946\n",
      "Epoch: 805, Iteration: 1/2, Loss: 1.3923428435313987\n",
      "Epoch: 806, Iteration: 1/2, Loss: 1.392232087509991\n",
      "Epoch: 807, Iteration: 1/2, Loss: 1.3919977436198208\n",
      "Epoch: 808, Iteration: 1/2, Loss: 1.3920208846700128\n",
      "Epoch: 809, Iteration: 1/2, Loss: 1.3919762251353542\n",
      "Epoch: 810, Iteration: 1/2, Loss: 1.3920557919235703\n",
      "Epoch: 811, Iteration: 1/2, Loss: 1.392252841085754\n",
      "Epoch: 812, Iteration: 1/2, Loss: 1.3922063026508464\n",
      "Epoch: 813, Iteration: 1/2, Loss: 1.3922551365906541\n",
      "Epoch: 814, Iteration: 1/2, Loss: 1.3918004934120038\n",
      "Epoch: 815, Iteration: 1/2, Loss: 1.391959772607116\n",
      "Epoch: 816, Iteration: 1/2, Loss: 1.3919619415184257\n",
      "Epoch: 817, Iteration: 1/2, Loss: 1.3916456378435038\n",
      "Epoch: 818, Iteration: 1/2, Loss: 1.3922078321033329\n",
      "Epoch: 819, Iteration: 1/2, Loss: 1.3921771983473445\n",
      "Epoch: 820, Iteration: 1/2, Loss: 1.3919688676690667\n",
      "Epoch: 821, Iteration: 1/2, Loss: 1.392234949579716\n",
      "Epoch: 822, Iteration: 1/2, Loss: 1.3918663006544665\n",
      "Epoch: 823, Iteration: 1/2, Loss: 1.3918889719428817\n",
      "Epoch: 824, Iteration: 1/2, Loss: 1.3919743095890575\n",
      "Epoch: 825, Iteration: 1/2, Loss: 1.3919957884320384\n",
      "Epoch: 826, Iteration: 1/2, Loss: 1.3915150211507836\n",
      "Epoch: 827, Iteration: 1/2, Loss: 1.391767512117088\n",
      "Epoch: 828, Iteration: 1/2, Loss: 1.3923391395547862\n",
      "Epoch: 829, Iteration: 1/2, Loss: 1.3917089907498716\n",
      "Epoch: 830, Iteration: 1/2, Loss: 1.3914769071010207\n",
      "Epoch: 831, Iteration: 1/2, Loss: 1.3920000226206395\n",
      "Epoch: 832, Iteration: 1/2, Loss: 1.3919042306131704\n",
      "Epoch: 833, Iteration: 1/2, Loss: 1.391786079508277\n",
      "Epoch: 834, Iteration: 1/2, Loss: 1.3919887767024604\n",
      "Epoch: 835, Iteration: 1/2, Loss: 1.3914893901446117\n",
      "Epoch: 836, Iteration: 1/2, Loss: 1.3917571891238167\n",
      "Epoch: 837, Iteration: 1/2, Loss: 1.3917756160826698\n",
      "Epoch: 838, Iteration: 1/2, Loss: 1.392450110623964\n",
      "Epoch: 839, Iteration: 1/2, Loss: 1.3916950606051137\n",
      "Epoch: 840, Iteration: 1/2, Loss: 1.39163793211606\n",
      "Epoch: 841, Iteration: 1/2, Loss: 1.3915752953727982\n",
      "Epoch: 842, Iteration: 1/2, Loss: 1.3914000416567012\n",
      "Epoch: 843, Iteration: 1/2, Loss: 1.3924536297617893\n",
      "Epoch: 844, Iteration: 1/2, Loss: 1.3916463167719884\n",
      "Epoch: 845, Iteration: 1/2, Loss: 1.391790337336028\n",
      "Epoch: 846, Iteration: 1/2, Loss: 1.3910639230883328\n",
      "Epoch: 847, Iteration: 1/2, Loss: 1.3922739262108643\n",
      "Epoch: 848, Iteration: 1/2, Loss: 1.3917431291736593\n",
      "Epoch: 849, Iteration: 1/2, Loss: 1.3913533276483203\n",
      "Epoch: 850, Iteration: 1/2, Loss: 1.3913334470995449\n",
      "Epoch: 851, Iteration: 1/2, Loss: 1.3919697787487582\n",
      "Epoch: 852, Iteration: 1/2, Loss: 1.3913495841548704\n",
      "Epoch: 853, Iteration: 1/2, Loss: 1.3920081602436274\n",
      "Epoch: 854, Iteration: 1/2, Loss: 1.391499324117237\n",
      "Epoch: 855, Iteration: 1/2, Loss: 1.3913747677304695\n",
      "Epoch: 856, Iteration: 1/2, Loss: 1.3917922686585955\n",
      "Epoch: 857, Iteration: 1/2, Loss: 1.3915989595636447\n",
      "Epoch: 858, Iteration: 1/2, Loss: 1.3914063293191918\n",
      "Epoch: 859, Iteration: 1/2, Loss: 1.391776455302197\n",
      "Epoch: 860, Iteration: 1/2, Loss: 1.3914957148661051\n",
      "Epoch: 861, Iteration: 1/2, Loss: 1.3915609278699836\n",
      "Epoch: 862, Iteration: 1/2, Loss: 1.3916120900536502\n",
      "Epoch: 863, Iteration: 1/2, Loss: 1.3917859427507544\n",
      "Epoch: 864, Iteration: 1/2, Loss: 1.391516637899874\n",
      "Epoch: 865, Iteration: 1/2, Loss: 1.391370330405036\n",
      "Epoch: 866, Iteration: 1/2, Loss: 1.3912454753605281\n",
      "Epoch: 867, Iteration: 1/2, Loss: 1.3918108143403112\n",
      "Epoch: 868, Iteration: 1/2, Loss: 1.3917492367133661\n",
      "Epoch: 869, Iteration: 1/2, Loss: 1.3911994720245977\n",
      "Epoch: 870, Iteration: 1/2, Loss: 1.3917219137347998\n",
      "Epoch: 871, Iteration: 1/2, Loss: 1.3911675348056114\n",
      "Epoch: 872, Iteration: 1/2, Loss: 1.3912682972393764\n",
      "Epoch: 873, Iteration: 1/2, Loss: 1.3918105058002692\n",
      "Epoch: 874, Iteration: 1/2, Loss: 1.3916925787340726\n",
      "Epoch: 875, Iteration: 1/2, Loss: 1.391318021558125\n",
      "Epoch: 876, Iteration: 1/2, Loss: 1.3909199056012844\n",
      "Epoch: 877, Iteration: 1/2, Loss: 1.3917157666171605\n",
      "Epoch: 878, Iteration: 1/2, Loss: 1.3913564410042352\n",
      "Epoch: 879, Iteration: 1/2, Loss: 1.3913549941441257\n",
      "Epoch: 880, Iteration: 1/2, Loss: 1.3913892230953882\n",
      "Epoch: 881, Iteration: 1/2, Loss: 1.3913239116764267\n",
      "Epoch: 882, Iteration: 1/2, Loss: 1.3917247359359008\n",
      "Epoch: 883, Iteration: 1/2, Loss: 1.3909973047517217\n",
      "Epoch: 884, Iteration: 1/2, Loss: 1.3917773549595251\n",
      "Epoch: 885, Iteration: 1/2, Loss: 1.3910512019962045\n",
      "Epoch: 886, Iteration: 1/2, Loss: 1.3916876019667104\n",
      "Epoch: 887, Iteration: 1/2, Loss: 1.3912726640186852\n",
      "Epoch: 888, Iteration: 1/2, Loss: 1.3911325324251498\n",
      "Epoch: 889, Iteration: 1/2, Loss: 1.3911500151817293\n",
      "Epoch: 890, Iteration: 1/2, Loss: 1.3915951221224612\n",
      "Epoch: 891, Iteration: 1/2, Loss: 1.390947626225163\n",
      "Epoch: 892, Iteration: 1/2, Loss: 1.3910868994499295\n",
      "Epoch: 893, Iteration: 1/2, Loss: 1.3913343311623594\n",
      "Epoch: 894, Iteration: 1/2, Loss: 1.3913259271697656\n",
      "Epoch: 895, Iteration: 1/2, Loss: 1.391749712007709\n",
      "Epoch: 896, Iteration: 1/2, Loss: 1.3909637803204329\n",
      "Epoch: 897, Iteration: 1/2, Loss: 1.3913904461168394\n",
      "Epoch: 898, Iteration: 1/2, Loss: 1.3910212276015024\n",
      "Epoch: 899, Iteration: 1/2, Loss: 1.3910449274182093\n",
      "Epoch: 900, Iteration: 1/2, Loss: 1.3914586016354784\n",
      "Epoch: 901, Iteration: 1/2, Loss: 1.391028259678801\n",
      "Epoch: 902, Iteration: 1/2, Loss: 1.3912901793435535\n",
      "Epoch: 903, Iteration: 1/2, Loss: 1.3911090547183043\n",
      "Epoch: 904, Iteration: 1/2, Loss: 1.3917224955283447\n",
      "Epoch: 905, Iteration: 1/2, Loss: 1.3908393428539516\n",
      "Epoch: 906, Iteration: 1/2, Loss: 1.391327692883452\n",
      "Epoch: 907, Iteration: 1/2, Loss: 1.3912886217934406\n",
      "Epoch: 908, Iteration: 1/2, Loss: 1.3906365096065811\n",
      "Epoch: 909, Iteration: 1/2, Loss: 1.391368925921162\n",
      "Epoch: 910, Iteration: 1/2, Loss: 1.3911384690365733\n",
      "Epoch: 911, Iteration: 1/2, Loss: 1.391370955372628\n",
      "Epoch: 912, Iteration: 1/2, Loss: 1.3908949278815037\n",
      "Epoch: 913, Iteration: 1/2, Loss: 1.3914494491536917\n",
      "Epoch: 914, Iteration: 1/2, Loss: 1.3905274317594816\n",
      "Epoch: 915, Iteration: 1/2, Loss: 1.391236565155689\n",
      "Epoch: 916, Iteration: 1/2, Loss: 1.3910789477865646\n",
      "Epoch: 917, Iteration: 1/2, Loss: 1.3915341718965473\n",
      "Epoch: 918, Iteration: 1/2, Loss: 1.39083091754781\n",
      "Epoch: 919, Iteration: 1/2, Loss: 1.3907488438259747\n",
      "Epoch: 920, Iteration: 1/2, Loss: 1.3915154209159777\n",
      "Epoch: 921, Iteration: 1/2, Loss: 1.39059788544683\n",
      "Epoch: 922, Iteration: 1/2, Loss: 1.391033254890499\n",
      "Epoch: 923, Iteration: 1/2, Loss: 1.391277440635263\n",
      "Epoch: 924, Iteration: 1/2, Loss: 1.3910288317514365\n",
      "Epoch: 925, Iteration: 1/2, Loss: 1.3909695430361109\n",
      "Epoch: 926, Iteration: 1/2, Loss: 1.3912049361551118\n",
      "Epoch: 927, Iteration: 1/2, Loss: 1.3909522851051324\n",
      "Epoch: 928, Iteration: 1/2, Loss: 1.390795388902316\n",
      "Epoch: 929, Iteration: 1/2, Loss: 1.3908799223494008\n",
      "Epoch: 930, Iteration: 1/2, Loss: 1.3913097298009793\n",
      "Epoch: 931, Iteration: 1/2, Loss: 1.3908116313497347\n",
      "Epoch: 932, Iteration: 1/2, Loss: 1.3911719469048704\n",
      "Epoch: 933, Iteration: 1/2, Loss: 1.3908212388897014\n",
      "Epoch: 934, Iteration: 1/2, Loss: 1.3909422666094684\n",
      "Epoch: 935, Iteration: 1/2, Loss: 1.3911061034454661\n",
      "Epoch: 936, Iteration: 1/2, Loss: 1.391111291847366\n",
      "Epoch: 937, Iteration: 1/2, Loss: 1.3903744285748818\n",
      "Epoch: 938, Iteration: 1/2, Loss: 1.3914161048345717\n",
      "Epoch: 939, Iteration: 1/2, Loss: 1.390658238346943\n",
      "Epoch: 940, Iteration: 1/2, Loss: 1.3911770260838334\n",
      "Epoch: 941, Iteration: 1/2, Loss: 1.3905706431060776\n",
      "Epoch: 942, Iteration: 1/2, Loss: 1.3912772190145595\n",
      "Epoch: 943, Iteration: 1/2, Loss: 1.3905675711843282\n",
      "Epoch: 944, Iteration: 1/2, Loss: 1.3906978086444295\n",
      "Epoch: 945, Iteration: 1/2, Loss: 1.3910901123903292\n",
      "Epoch: 946, Iteration: 1/2, Loss: 1.3908196070606893\n",
      "Epoch: 947, Iteration: 1/2, Loss: 1.3911332946321093\n",
      "Epoch: 948, Iteration: 1/2, Loss: 1.3908022085479166\n",
      "Epoch: 949, Iteration: 1/2, Loss: 1.3906738933437746\n",
      "Epoch: 950, Iteration: 1/2, Loss: 1.390572569641611\n",
      "Epoch: 951, Iteration: 1/2, Loss: 1.390830303535169\n",
      "Epoch: 952, Iteration: 1/2, Loss: 1.3911378632232942\n",
      "Epoch: 953, Iteration: 1/2, Loss: 1.3907084000625929\n",
      "Epoch: 954, Iteration: 1/2, Loss: 1.3910704812909795\n",
      "Epoch: 955, Iteration: 1/2, Loss: 1.3905493975875263\n",
      "Epoch: 956, Iteration: 1/2, Loss: 1.3911071418256116\n",
      "Epoch: 957, Iteration: 1/2, Loss: 1.3907259550888005\n",
      "Epoch: 958, Iteration: 1/2, Loss: 1.3904819408754032\n",
      "Epoch: 959, Iteration: 1/2, Loss: 1.3909548616010405\n",
      "Epoch: 960, Iteration: 1/2, Loss: 1.3906225857520147\n",
      "Epoch: 961, Iteration: 1/2, Loss: 1.3910186934243183\n",
      "Epoch: 962, Iteration: 1/2, Loss: 1.3903956501912669\n",
      "Epoch: 963, Iteration: 1/2, Loss: 1.390745768964004\n",
      "Epoch: 964, Iteration: 1/2, Loss: 1.3906701526854017\n",
      "Epoch: 965, Iteration: 1/2, Loss: 1.3907328362685094\n",
      "Epoch: 966, Iteration: 1/2, Loss: 1.3909965138772367\n",
      "Epoch: 967, Iteration: 1/2, Loss: 1.3904019804679466\n",
      "Epoch: 968, Iteration: 1/2, Loss: 1.3906614209283594\n",
      "Epoch: 969, Iteration: 1/2, Loss: 1.3912236259670308\n",
      "Epoch: 970, Iteration: 1/2, Loss: 1.3905333572735814\n",
      "Epoch: 971, Iteration: 1/2, Loss: 1.3906450150330638\n",
      "Epoch: 972, Iteration: 1/2, Loss: 1.3909038835552157\n",
      "Epoch: 973, Iteration: 1/2, Loss: 1.3905049736378725\n",
      "Epoch: 974, Iteration: 1/2, Loss: 1.390798022963172\n",
      "Epoch: 975, Iteration: 1/2, Loss: 1.3904114535076055\n",
      "Epoch: 976, Iteration: 1/2, Loss: 1.3907978593018189\n",
      "Epoch: 977, Iteration: 1/2, Loss: 1.3902896246926268\n",
      "Epoch: 978, Iteration: 1/2, Loss: 1.3910069804525513\n",
      "Epoch: 979, Iteration: 1/2, Loss: 1.3905357324265926\n",
      "Epoch: 980, Iteration: 1/2, Loss: 1.390373920100976\n",
      "Epoch: 981, Iteration: 1/2, Loss: 1.390846739174087\n",
      "Epoch: 982, Iteration: 1/2, Loss: 1.3908691424741544\n",
      "Epoch: 983, Iteration: 1/2, Loss: 1.390236607518852\n",
      "Epoch: 984, Iteration: 1/2, Loss: 1.3909816235540275\n",
      "Epoch: 985, Iteration: 1/2, Loss: 1.390644049238864\n",
      "Epoch: 986, Iteration: 1/2, Loss: 1.3904231959512532\n",
      "Epoch: 987, Iteration: 1/2, Loss: 1.3903371476901358\n",
      "Epoch: 988, Iteration: 1/2, Loss: 1.3909896485979716\n",
      "Epoch: 989, Iteration: 1/2, Loss: 1.3902399400928724\n",
      "Epoch: 990, Iteration: 1/2, Loss: 1.390900392224991\n",
      "Epoch: 991, Iteration: 1/2, Loss: 1.39052490373773\n",
      "Epoch: 992, Iteration: 1/2, Loss: 1.3902581608523394\n",
      "Epoch: 993, Iteration: 1/2, Loss: 1.390684357983468\n",
      "Epoch: 994, Iteration: 1/2, Loss: 1.3907939583949964\n",
      "Epoch: 995, Iteration: 1/2, Loss: 1.3903190849957756\n",
      "Epoch: 996, Iteration: 1/2, Loss: 1.390349686398984\n",
      "Epoch: 997, Iteration: 1/2, Loss: 1.390566296207391\n",
      "Epoch: 998, Iteration: 1/2, Loss: 1.390665533509813\n",
      "Epoch: 999, Iteration: 1/2, Loss: 1.3903190237495735\n",
      "Epoch: 1000, Iteration: 1/2, Loss: 1.3905607171514665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "\n",
    "# configurations\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "# define model\n",
    "skip_gram = SkipGram(vocab_size=len(word2idx), hidden_size=hidden_size, window_size=window_size)\n",
    "sgd_optimizer = SGD()\n",
    "trainer = Trainer(skip_gram, sgd_optimizer)\n",
    "\n",
    "# start training\n",
    "trainer.fit(contexts, targets, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studying [ 0.03509983  0.51529443 -0.9742502   1.727418    2.0924873 ]\n",
      "language [ 0.14458317  1.736226    0.7649951   2.6704128  -0.12764466]\n",
      "i [ 0.01455147 -0.00225844 -0.00152124 -0.00155948 -0.0171884 ]\n",
      "processing [ 0.64390135 -1.6839404  -1.3443768  -0.9909441  -1.7128546 ]\n",
      "natural [ 0.49661285 -2.2259881   0.7061572  -2.037493    0.51091766]\n",
      "now [-0.49245292  0.77452797  0.9208236   0.89182234 -2.5126684 ]\n",
      ". [ 0.00443482  0.00116071 -0.00473972  0.01033234  0.00074891]\n",
      "am [-0.550826    0.53903264  0.5082179  -2.0508063   1.8738655 ]\n"
     ]
    }
   ],
   "source": [
    "# check skip-gram results\n",
    "word_vecs = skip_gram.word_vecs\n",
    "for word_id, word in idx2word.items():\n",
    "    print(word, word_vecs[word_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupoy_env",
   "language": "python",
   "name": "cupoy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
