{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"CH39_作業.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"bWmYuIqwXky9"},"source":["# 作業 : 自行調整完整版 Bert 預訓練模型"]},{"cell_type":"markdown","metadata":{"id":"pjR0X3RKXkzH"},"source":["# [作業目標]\n","- 觀察並了解調整 Step4.3 類神經網路結構對結果帶來的影響\n","- 觀察並了解調整 Step4.2 Batch Size 以及 Step4.4 的Optimizer & Learning Rate 對結果帶來的影響"]},{"cell_type":"markdown","metadata":{"id":"G9OcW6i0XkzI"},"source":["# [作業重點]\n","- 程式最後會輸出 Kaggle 練習題的提交檔, 同學可以藉由提交分數驗證結果\n","- 請同學在修改時, 記得以檔名或其他形式保留調整的紀錄, 以免忘記最佳輸出的調整方式"]},{"cell_type":"markdown","metadata":{"id":"5HiLyC9ZXkzJ"},"source":["# 載入資料與套件, 進行切割與預處理"]},{"cell_type":"code","metadata":{"id":"eVDiQwbCXkzJ"},"source":["# 載入相關套件\n","import os\n","import re, warnings\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","warnings.filterwarnings(\"ignore\")\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UngfxH5AXkzK"},"source":["# 將訓練資料切割成 訓練集 / 驗證集\n","from sklearn.model_selection import train_test_split\n","\n","df =  pd.read_csv('data/train.csv')\n","X = df.text.values\n","y = df.target.values\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=2020)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v6PqS3WeXkzK","outputId":"90eef939-d7c3-4160-8948-33839e178970"},"source":["# 載入測試資料\n","test_df = pd.read_csv('data/test.csv')\n","test_df = test_df[['id', 'text']]\n","test_df.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>486</td>\n","      <td>1581</td>\n","      <td>ÛÏTell Shinichi Kudo that IÛªm giving him 3 ...</td>\n","    </tr>\n","    <tr>\n","      <td>911</td>\n","      <td>2997</td>\n","      <td>@_ToneDidIt this can't be real nah ?? her moth...</td>\n","    </tr>\n","    <tr>\n","      <td>1488</td>\n","      <td>4947</td>\n","      <td>If that was ronaldo Twitter would have exploded</td>\n","    </tr>\n","    <tr>\n","      <td>1959</td>\n","      <td>6606</td>\n","      <td>[Brutally Honest Technology ]\\n\\nDay after day...</td>\n","    </tr>\n","    <tr>\n","      <td>2255</td>\n","      <td>7500</td>\n","      <td>#breaking #LA Refugio oil spill may have been ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id                                               text\n","486   1581  ÛÏTell Shinichi Kudo that IÛªm giving him 3 ...\n","911   2997  @_ToneDidIt this can't be real nah ?? her moth...\n","1488  4947    If that was ronaldo Twitter would have exploded\n","1959  6606  [Brutally Honest Technology ]\\n\\nDay after day...\n","2255  7500  #breaking #LA Refugio oil spill may have been ..."]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"e_wESyxZXkzM","outputId":"3631d01d-fedf-43fb-b621-54cf12e0ad06"},"source":["# 載入 pytorch 套件, 依照現有環境判定是否使用 GPU 計算\n","import torch\n","\n","if torch.cuda.is_available():       \n","    device = torch.device(\"cuda\")\n","    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n","    print('Device name:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["No GPU available, using the CPU instead.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4P4Azey2XkzN"},"source":["# 簡化版前處理\n","def text_preprocessing(text):\n","    # 移除推特的姓名標籤 ('@name')\n","    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n","    # 將 '&amp;' 替換成 '&'\n","    text = re.sub(r'&amp;', '&', text)\n","    # 移除文末的空白字元\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RdhdTZhXXkzN","outputId":"ff15215a-c612-4312-b456-665794f8782c"},"source":["# 印出第一組推文在前處理之前與之後的改變\n","print('Original: ', X[0])\n","print('Processed: ', text_preprocessing(X[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n","Processed:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FZYjqFAZXkzN"},"source":["# Step 4.1 : 載入 Bert 套件與 tokenizer, 將本文編碼"]},{"cell_type":"code","metadata":{"id":"dnA2rPKYXkzO"},"source":["# 載入 Bert 套件與 tokenizer\n","from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","# 設定 Bert 的前處理函數\n","def preprocessing_for_bert(data):\n","    # 初始化要傳回的資料\n","    input_ids = []\n","    attention_masks = []\n","    # 把所有文句用 tokenizer 編碼\n","    for sent in data:\n","        encoded_sent = tokenizer.encode_plus(\n","            text=text_preprocessing(sent),  # 套用簡化版前處理函數\n","            add_special_tokens=True,        # 加上 `[CLS]` 與 `[SEP]`\n","            max_length=MAX_LEN,             # 需要填充的最大長度\n","            pad_to_max_length=True,         # 是否要填充到最大長度\n","            return_attention_mask=True      # 是否傳回 attention mask\n","            )        \n","        # 更新要傳回的資料\n","        input_ids.append(encoded_sent.get('input_ids'))\n","        attention_masks.append(encoded_sent.get('attention_mask'))\n","    # 將傳回資料轉為 tensor\n","    input_ids = torch.tensor(input_ids)\n","    attention_masks = torch.tensor(attention_masks)\n","\n","    return input_ids, attention_masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D9ezEZMyXkzO","outputId":"3b5100be-1747-4ea5-acf2-43b58b21d161"},"source":["# 將訓練資料與測試資料的\"推文\"合併\n","all_tweets = np.concatenate([df.text.values, test_df.text.values])\n","\n","# 將推文使用 tokenizer 加以編碼\n","encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n","\n","# 找出最大的推文長度 (訓練資料 + 預測目標資料)\n","max_len = max([len(sent) for sent in encoded_tweets])\n","print('Max length: ', max_len)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Max length:  84\n","Max length:  84\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ov-IWDOKXkzP","outputId":"3a54abe2-5cd5-4061-ab2e-5ce65dc4a451"},"source":["# 將上一格的 Max length 數值填入\n","MAX_LEN = 84\n","\n","# 顯示第一筆資料的推文與期經過 Bert 的前處理函數 (preprocessing_for_bert) 的編碼結果 (確認函數正確)\n","token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n","print('Original: ', X[0])\n","print('Token IDs: ', token_ids)\n","\n","# 使用 preprocessing_for_bert 將訓練 / 驗證集的推文進行編碼\n","print('Tokenizing data...')\n","train_inputs, train_masks = preprocessing_for_bert(X_train)\n","val_inputs, val_masks = preprocessing_for_bert(X_val)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","C:\\Users\\walkwall\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n","Token IDs:  [101, 2256, 15616, 2024, 1996, 3114, 1997, 2023, 1001, 8372, 2089, 16455, 9641, 2149, 2035, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Tokenizing data...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zY6IgL0KXkzP"},"source":["# Step 4.2 : Fine Tune 前的準備 - 設定 batch size"]},{"cell_type":"code","metadata":{"id":"2iDpz5UUXkzQ"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# 將訓練與驗證目標值轉為 torch.Tensor\n","train_labels = torch.tensor(y_train)\n","val_labels = torch.tensor(y_val)\n","\n","# 要微調 (fine-tuning) BERT 時, 原作者建議的 batch size 為 16 或 32\n","batch_size = 32\n","\n","# 設定訓練與驗證集的 DataLoader\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xFNtfKhaXkzQ"},"source":["# Step 4.3 : 設定 Bert 連接目標值的 Layer 結構"]},{"cell_type":"code","metadata":{"id":"gyE5aOSjXkzR","outputId":"482ec518-9650-414e-9ca4-bee0cb27cdac"},"source":["%%time\n","# 載入 pytorch 與 Bert 相關套件\n","import torch\n","import torch.nn as nn\n","from transformers import BertModel\n","\n","# 自定義 Bert 分類器函數\n","class BertClassifier(nn.Module):\n","    def __init__(self, freeze_bert=False):\n","        super(BertClassifier, self).__init__()\n","        # 指定 BERT 輸入長度大小(D_in), 分類器的隱藏層大小(H), 以及分類目標值的種類數量(D_out)\n","        D_in, H, D_out = 768, 50, 2\n","        # 載入 Bert 預訓練權重作為初始值\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","\n","        # 初始化自定義分類器的類神經網路\n","        self.classifier = nn.Sequential(\n","            nn.Linear(D_in, H),\n","            nn.ReLU(),\n","            #nn.Dropout(0.5),\n","            nn.Linear(H, D_out)\n","        )\n","        # 凍結 Bert 部分的權重\n","        if freeze_bert:\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","        \n","    def forward(self, input_ids, attention_mask):\n","        # 將資料輸入 BERT\n","        outputs = self.bert(input_ids=input_ids,\n","                            attention_mask=attention_mask)        \n","        # 將輸出結果存在 last_hidden_state_cls 中\n","        last_hidden_state_cls = outputs[0][:, 0, :]\n","        # 將輸出結果輸入自定義分類器\n","        logits = self.classifier(last_hidden_state_cls)\n","\n","        return logits"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Wall time: 22.3 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VOxS-dcOXkzS"},"source":["# Step 4.4 : Optimizer & Learning Rate"]},{"cell_type":"code","metadata":{"id":"g6ihaa8zXkzS"},"source":["from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","def initialize_model(epochs=4):\n","    # 初始化 Bert 分類器\n","    bert_classifier = BertClassifier(freeze_bert=False)\n","    # 告訴 PyTorch 模型需要在 GPU 上執行\n","    bert_classifier.to(device)\n","    # 設定 optimizer\n","    optimizer = AdamW(bert_classifier.parameters(),\n","                      lr=5e-5,    # 預設的學習速率\n","                      eps=1e-8    # 預設的 epsilon 值\n","                      )\n","    # 計算總共的訓練步數\n","    total_steps = len(train_dataloader) * epochs\n","    # 設定學習率排程\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0, # 預設值\n","                                                num_training_steps=total_steps)\n","    return bert_classifier, optimizer, scheduler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5YvwYTdLXkzT"},"source":["import random\n","import time\n","\n","# 設定損失函數\n","loss_fn = nn.CrossEntropyLoss()\n","def set_seed(seed_value=42):\n","    random.seed(seed_value)\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)\n","def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n","    # 開始訓練迴圈\n","    print(\"Start training...\\n\")\n","    for epoch_i in range(epochs):\n","        # 印出變數表格標題\n","        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n","        print(\"-\"*70)\n","        # 測量每個 epoch 的執行時間\n","        t0_epoch, t0_batch = time.time(), time.time()\n","        # 每個 epoch 開始時重置追蹤的變數\n","        total_loss, batch_loss, batch_counts = 0, 0, 0\n","        # 將模型切換到訓練模式\n","        model.train()\n","        # 訓練資料的每個 batch \n","        for step, batch in enumerate(train_dataloader):\n","            batch_counts +=1\n","            # 將所有 batch 資料載入 GPU\n","            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","            # 將模型中之前計算的梯度歸零\n","            model.zero_grad()\n","            # 執行一個向前傳遞. 這會傳回一個 logit 值\n","            logits = model(b_input_ids, b_attn_mask)\n","            # 計算並累加損失值\n","            loss = loss_fn(logits, b_labels)\n","            batch_loss += loss.item()\n","            total_loss += loss.item()\n","            # 執行一個向後傳遞以計算梯度\n","            loss.backward()\n","            # 將梯度侷限在正負 1 範圍內, 防止梯度爆炸\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            # 更新參數與學習率\n","            optimizer.step()\n","            scheduler.step()\n","            # 每 20 個 batches 印出損失值與執行時間一次\n","            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n","                # 計算 20 batches 的執行時間\n","                time_elapsed = time.time() - t0_batch\n","                # 印出訓練結果\n","                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n","                # 重置 batch 追蹤變數\n","                batch_loss, batch_counts = 0, 0\n","                t0_batch = time.time()\n","        # 計算全部訓練資料的平均損失值\n","        avg_train_loss = total_loss / len(train_dataloader)\n","\n","        print(\"-\"*70)\n","        if evaluation == True:\n","            # 每個 epoch 訓練完畢後, 在驗證集上檢驗模型的表現\n","            val_loss, val_accuracy = evaluate(model, val_dataloader)\n","            time_elapsed = time.time() - t0_epoch            \n","            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n","            print(\"-\"*70)\n","        print(\"\\n\")    \n","    print(\"Training complete!\")\n","\n","def evaluate(model, val_dataloader):\n","    # 將模型切換到評量模式 : 此模式下暫停使用 dropout 層\n","    model.eval()\n","    # 紀錄評量函數\n","    val_accuracy = []\n","    val_loss = []\n","    # 驗證資料的每個 batch \n","    for batch in val_dataloader:\n","        # 將所有 batch 資料載入 GPU\n","        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","        # 計算 logit 值\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","        # 計算損失值\n","        loss = loss_fn(logits, b_labels)\n","        val_loss.append(loss.item())\n","        # 取得預測值\n","        preds = torch.argmax(logits, dim=1).flatten()\n","        # 計算 accuracy 數值\n","        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n","        val_accuracy.append(accuracy)\n","    # 計算全部驗證資料的平均損失值與平均 accuracy\n","    val_loss = np.mean(val_loss)\n","    val_accuracy = np.mean(val_accuracy)\n","    return val_loss, val_accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mkh_UvM2XkzU"},"source":["# 執行跑參 : 依機器的計算能力調整 epoch 大小"]},{"cell_type":"code","metadata":{"id":"F2pkguY7XkzU","outputId":"e1fc96d0-dda8-494e-8038-f3e88b54a25c"},"source":["set_seed(42) # 設定隨機種子\n","bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n","train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Start training...\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   1    |   20    |   0.561860   |     -      |     -     |  143.73  \n","   1    |   40    |   0.463885   |     -      |     -     |  127.68  \n","   1    |   60    |   0.468251   |     -      |     -     |  122.30  \n","   1    |   80    |   0.436385   |     -      |     -     |  127.54  \n","   1    |   100   |   0.419725   |     -      |     -     |  135.76  \n","   1    |   120   |   0.465260   |     -      |     -     |  142.95  \n","   1    |   140   |   0.421594   |     -      |     -     |  149.14  \n","   1    |   160   |   0.353918   |     -      |     -     |  144.31  \n","   1    |   180   |   0.408150   |     -      |     -     |  142.61  \n","   1    |   200   |   0.440857   |     -      |     -     |  141.98  \n","   1    |   214   |   0.370597   |     -      |     -     |   90.15  \n","----------------------------------------------------------------------\n","   1    |    -    |   0.439758   |  0.414609  |   82.04   |  1522.04 \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   2    |   20    |   0.310375   |     -      |     -     |  149.57  \n","   2    |   40    |   0.276240   |     -      |     -     |  140.17  \n","   2    |   60    |   0.312829   |     -      |     -     |  141.44  \n","   2    |   80    |   0.260810   |     -      |     -     |  147.64  \n","   2    |   100   |   0.330842   |     -      |     -     |  140.72  \n","   2    |   120   |   0.299862   |     -      |     -     |  146.94  \n","   2    |   140   |   0.269373   |     -      |     -     |  143.93  \n","   2    |   160   |   0.286334   |     -      |     -     |  139.25  \n","   2    |   180   |   0.245135   |     -      |     -     |  148.91  \n","   2    |   200   |   0.273767   |     -      |     -     |  148.07  \n","   2    |   214   |   0.341850   |     -      |     -     |   97.99  \n","----------------------------------------------------------------------\n","   2    |    -    |   0.290268   |  0.454192  |   81.81   |  1598.59 \n","----------------------------------------------------------------------\n","\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EaxNnaM4XkzU"},"source":["# 繪製 ROC_AUC 圖形 : 藉此觀察預測效果"]},{"cell_type":"code","metadata":{"id":"phdGa5X5XkzU"},"source":["import torch.nn.functional as F\n","\n","def bert_predict(model, test_dataloader):\n","    # 將模型切換到評量模式 : 此模式下暫停使用 dropout 層\n","    model.eval()\n","    all_logits = []\n","\n","    # 測試資料的每個 batch \n","    for batch in test_dataloader:\n","        # 將所有 batch 資料載入 GPU\n","        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n","        # 計算機率\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","        all_logits.append(logits)    \n","    # 將每個 batch 的 logit 值連結起來\n","    all_logits = torch.cat(all_logits, dim=0)\n","    # 使用 softmax 計算機率\n","    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n","    return probs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2nK6w-NyXkzV"},"source":["from sklearn.metrics import accuracy_score, roc_curve, auc\n","\n","def evaluate_roc(probs, y_true):\n","    preds = probs[:, 1]\n","    fpr, tpr, threshold = roc_curve(y_true, preds)\n","    roc_auc = auc(fpr, tpr)\n","    print(f'AUC: {roc_auc:.4f}')       \n","    # 取得測試集的 accuracy 值\n","    y_pred = np.where(preds >= 0.5, 1, 0)\n","    accuracy = accuracy_score(y_true, y_pred)\n","    print(f'Accuracy: {accuracy*100:.2f}%')    \n","    # 繪製 ROC AUC\n","    plt.title('Receiver Operating Characteristic')\n","    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n","    plt.legend(loc = 'lower right')\n","    plt.plot([0, 1], [0, 1],'r--')\n","    plt.xlim([0, 1])\n","    plt.ylim([0, 1])\n","    plt.ylabel('True Positive Rate')\n","    plt.xlabel('False Positive Rate')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r5Rx4KwpXkzV","outputId":"1ce346fb-73ac-45f7-ddfe-1608d472f11f"},"source":["# 在測試集上計算預測機率\n","probs = bert_predict(bert_classifier, val_dataloader)\n","# 評價 Bert 分類器\n","evaluate_roc(probs, y_val)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["AUC: 0.8839\n","Accuracy: 81.76%\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"o3FtqgxMXkzW"},"source":["# 重新以完整資料訓練模型, 並對要預測的資料進行輸出"]},{"cell_type":"code","metadata":{"id":"B0KT0n72XkzW","outputId":"0690e62d-8e90-4929-d9eb-416218c67836"},"source":["# 連結訓練集與驗證集\n","full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n","full_train_sampler = RandomSampler(full_train_data)\n","full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n","\n","# 在完整的訓練資料上重新訓練 Bert 分類器\n","set_seed(42)\n","bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n","train(bert_classifier, full_train_dataloader, epochs=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Start training...\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   1    |   20    |   0.559687   |     -      |     -     |  148.69  \n","   1    |   40    |   0.484134   |     -      |     -     |  140.85  \n","   1    |   60    |   0.432558   |     -      |     -     |  143.69  \n","   1    |   80    |   0.473842   |     -      |     -     |  146.08  \n","   1    |   100   |   0.446571   |     -      |     -     |  189.14  \n","   1    |   120   |   0.420592   |     -      |     -     |  193.30  \n","   1    |   140   |   0.373169   |     -      |     -     |  191.74  \n","   1    |   160   |   0.361918   |     -      |     -     |  151.75  \n","   1    |   180   |   0.376631   |     -      |     -     |  141.82  \n","   1    |   200   |   0.436031   |     -      |     -     |  146.53  \n","   1    |   220   |   0.424235   |     -      |     -     |  143.19  \n","   1    |   237   |   0.406735   |     -      |     -     |  117.17  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   2    |   20    |   0.320365   |     -      |     -     |  145.10  \n","   2    |   40    |   0.279413   |     -      |     -     |  120.15  \n","   2    |   60    |   0.341654   |     -      |     -     |  125.81  \n","   2    |   80    |   0.324329   |     -      |     -     |  133.05  \n","   2    |   100   |   0.323088   |     -      |     -     |  147.66  \n","   2    |   120   |   0.264204   |     -      |     -     |  147.89  \n","   2    |   140   |   0.286298   |     -      |     -     |  145.59  \n","   2    |   160   |   0.270984   |     -      |     -     |  147.62  \n","   2    |   180   |   0.266612   |     -      |     -     |  120.58  \n","   2    |   200   |   0.299352   |     -      |     -     |  118.99  \n","   2    |   220   |   0.263588   |     -      |     -     |  119.14  \n","   2    |   237   |   0.319233   |     -      |     -     |  102.24  \n","----------------------------------------------------------------------\n","\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42F9JoIzXkzX","outputId":"a8eadd83-1c74-4a55-860f-b85303299d1d"},"source":["test_df.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2406</td>\n","      <td>8051</td>\n","      <td>Refugees as citizens - The Hindu http://t.co/G...</td>\n","    </tr>\n","    <tr>\n","      <td>134</td>\n","      <td>425</td>\n","      <td>@5SOStag honestly he could say an apocalypse i...</td>\n","    </tr>\n","    <tr>\n","      <td>411</td>\n","      <td>1330</td>\n","      <td>If you bored as shit don't nobody fuck wit you...</td>\n","    </tr>\n","    <tr>\n","      <td>203</td>\n","      <td>663</td>\n","      <td>@RealTwanBrown Yesterday I Had A Heat Attack ?...</td>\n","    </tr>\n","    <tr>\n","      <td>889</td>\n","      <td>2930</td>\n","      <td>The Devil Wears Prada is still one of my favou...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id                                               text\n","2406  8051  Refugees as citizens - The Hindu http://t.co/G...\n","134    425  @5SOStag honestly he could say an apocalypse i...\n","411   1330  If you bored as shit don't nobody fuck wit you...\n","203    663  @RealTwanBrown Yesterday I Had A Heat Attack ?...\n","889   2930  The Devil Wears Prada is still one of my favou..."]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"8imzaomzXkzY","outputId":"9697ebf1-e213-4ebc-b646-ba3b1fbc6a67"},"source":["# 在測試集推文上執行 `preprocessing_for_bert` 函數\n","print('Tokenizing data...')\n","test_inputs, test_masks = preprocessing_for_bert(test_df['text'])\n","# 宣告測試集的 DataLoader\n","test_dataset = TensorDataset(test_inputs, test_masks)\n","test_sampler = SequentialSampler(test_dataset)\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tokenizing data...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AM4o-sxDXkzZ","outputId":"597f6499-e02a-4c4b-c729-d53068768755"},"source":["# 在測試資料上計算最終預測機率\n","probs = bert_predict(bert_classifier, test_dataloader)\n","# 將機率值轉為預測(超過門檻的預測為 1, 否則為 0)\n","threshold = 0.9\n","preds = np.where(probs[:, 1] > threshold, 1, 0)\n","# 顯示被判定為\n","print(\"Number of tweets predicted non-negative: \", preds.sum())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of tweets predicted non-negative:  956\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mtjcf_WwXkza"},"source":["# 生成提交擋\n","submission = pd.DataFrame()\n","submission['id'] = test_df['id']\n","submission['target'] = preds\n","submission.to_csv('submission_FineTuneBert.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T_a_1BDeXkza"},"source":[""],"execution_count":null,"outputs":[]}]}