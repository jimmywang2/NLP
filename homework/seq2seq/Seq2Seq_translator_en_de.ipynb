{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"作業_Seq2Seq_translator_en_de.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMOcgmArzDbrFQT41e30AUD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"SrWWUhFlUprI"},"source":["# 作業 : 實作英文-德文翻譯機器人\n","***\n","## [作業目標]\n","\n","用 pytorch 實作一個英文-德文翻譯機器人\n","\n","## [作業目標]\n","\n","*   語言資料處理\n","*   使用 LSTM 建構 Encoder: EncoderLSTM\n","*   使用 LSTM 建構 Decoder: DecoderLSTM\n","*   搭建 Sequence to Sequence 模型: Seq2Seq\n","*   撰寫訓練函式\n","*   撰寫測試函式\n","\n","## [問題]\n","\n","在 Colab 實際上執行完這個範例後，請改用 BiLSTM 來建構 Encoder 與 Decoder\n"]},{"cell_type":"markdown","metadata":{"id":"XgPfcYR26SxF"},"source":["## 安裝 spacy\n","\n","We'll also make use of spaCy to tokenize our data. To install spaCy, follow the instructions here making sure to install both the English and German models with:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lzjl5xnFTm6l","executionInfo":{"status":"ok","timestamp":1610896283187,"user_tz":-480,"elapsed":11797,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"cc2486db-a189-4bc4-9cd3-1a47d6a4e9e7"},"source":["!pip uninstall spacy -y\n","!pip install -U spacy"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Uninstalling spacy-2.2.4:\n","  Successfully uninstalled spacy-2.2.4\n","Collecting spacy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/bf/ca7bb25edd21f1cf9d498d0023808279672a664a70585e1962617ca2740c/spacy-2.3.5-cp36-cp36m-manylinux2014_x86_64.whl (10.4MB)\n","\u001b[K     |████████████████████████████████| 10.4MB 5.7MB/s \n","\u001b[?25hCollecting thinc<7.5.0,>=7.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/1a/c3e4ab982214c63d743fad57c45c5e68ee49e4ea4384d27b28595a26ad26/thinc-7.4.5-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 39.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.19.5)\n","Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.5)\n","Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (51.1.1)\n","Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.5)\n","Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n","Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.3.0)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n","Installing collected packages: thinc, spacy\n","  Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","Successfully installed spacy-2.3.5 thinc-7.4.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qyd4LijE7vGo"},"source":["## 引用需要的模組"]},{"cell_type":"code","metadata":{"id":"RanKHsWTu-rn","executionInfo":{"status":"ok","timestamp":1610896287637,"user_tz":-480,"elapsed":16240,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}}},"source":["import jieba\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchtext.datasets import Multi30k\n","from torchtext.data import Field, BucketIterator\n","import numpy as np\n","import pandas as pd\n","import spacy\n","import random\n","# from torchtext.data.metrics import bleu_score\n","from pprint import pprint\n","from torch.utils.tensorboard import SummaryWriter\n","from torchsummary import summary"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a9h9rmgr74Sk"},"source":["## 下載英文預料"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XyskUGjGSr-0","executionInfo":{"status":"ok","timestamp":1610896300715,"user_tz":-480,"elapsed":29312,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"6f751eeb-ee66-4125-efac-31e1fa41c273"},"source":["!mkdir ./data\n","!mkdir ./data/multi30k\n","!python -m spacy download en\n","!ls ./data/multi30k -al\n","spacy_english = spacy.load(\"en\")\n","!ls ./data/multi30k -al"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting en_core_web_sm==2.3.1\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0MB)\n","\u001b[K     |████████████████████████████████| 12.1MB 679kB/s \n","\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.3.1) (2.3.5)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.41.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.23.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (51.1.1)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n","Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.3.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.4.0)\n","Building wheels for collected packages: en-core-web-sm\n","  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-cp36-none-any.whl size=12047109 sha256=6109a8b6d5f3e8d40cd2de290822036bfe8a8676585eec2182bd1f33fedb6593\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-oqp3let9/wheels/2b/3f/41/f0b92863355c3ba34bb32b37d8a0c662959da0058202094f46\n","Successfully built en-core-web-sm\n","Installing collected packages: en-core-web-sm\n","  Found existing installation: en-core-web-sm 2.2.5\n","    Uninstalling en-core-web-sm-2.2.5:\n","      Successfully uninstalled en-core-web-sm-2.2.5\n","Successfully installed en-core-web-sm-2.3.1\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n","total 8\n","drwxr-xr-x 2 root root 4096 Jan 17 15:11 .\n","drwxr-xr-x 3 root root 4096 Jan 17 15:11 ..\n","total 8\n","drwxr-xr-x 2 root root 4096 Jan 17 15:11 .\n","drwxr-xr-x 3 root root 4096 Jan 17 15:11 ..\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SBestLOF8L4w"},"source":["## 下載德語語料"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Hjr_6AXTRoz","executionInfo":{"status":"ok","timestamp":1610896422647,"user_tz":-480,"elapsed":12649,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"c9668d6c-95a5-4c79-f817-e4f61a0730d7"},"source":["!python -m spacy download de\n","spacy_de = spacy.load(\"de\")\n","!ls ./data/multi30k -al"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting de_core_news_sm==2.3.0\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.3.0/de_core_news_sm-2.3.0.tar.gz (14.9MB)\n","\u001b[K     |████████████████████████████████| 14.9MB 723kB/s \n","\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.3.0) (2.3.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.5)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.19.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.41.1)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.4.1)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.1.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (51.1.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.23.0)\n","Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (7.4.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.8.0)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.3.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.4)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.4.0)\n","Building wheels for collected packages: de-core-news-sm\n","  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.3.0-cp36-none-any.whl size=14907582 sha256=5b62ef677f270a5c7b9a3d7b35f49585a9abffc3659d8175762bc8c411398c99\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-epv9i5d6/wheels/db/f3/1e/0df0f27eee12bd1aaa94bcfef11b01eca62f90b9b9a0ce08fd\n","Successfully built de-core-news-sm\n","Installing collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-2.3.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('de_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/de\n","You can now load the model via spacy.load('de')\n","total 8\n","drwxr-xr-x 2 root root 4096 Jan 17 15:11 .\n","drwxr-xr-x 3 root root 4096 Jan 17 15:11 ..\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dK984GbYv8Y-","executionInfo":{"status":"ok","timestamp":1610896841532,"user_tz":-480,"elapsed":4170,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"029f2021-7519-4526-fa1f-ddf44106cf1b"},"source":["\n","def tokenize_de(text):\n","  return [token.text for token in spacy_de.tokenizer(text)]\n","\n","def tokenize_english(text):\n","  return [token.text for token in spacy_english.tokenizer(text)]\n","\n","### Sample Run ###\n","\n","sample_text = \"I love machine learning\"\n","print(tokenize_english(sample_text))\n","\n","german = Field(tokenize=tokenize_de, lower=True,\n","               init_token=\"<sos>\", eos_token=\"<eos>\")\n","\n","english = Field(tokenize=tokenize_english, lower=True,\n","               init_token=\"<sos>\", eos_token=\"<eos>\")\n","\n","train_data, valid_data, test_data = Multi30k.splits(exts = (\".en\", \".en\"),\n","                                                    fields=(german, english))\n","\n","german.build_vocab(train_data, max_size=10000, min_freq=3)\n","english.build_vocab(train_data, max_size=10000, min_freq=3)\n","\n","print(f\"Unique tokens in source (german) vocabulary: {len(german.vocab)}\")\n","print(f\"Unique tokens in target (en) vocabulary: {len(english.vocab)}\")\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["['I', 'love', 'machine', 'learning']\n","Unique tokens in source (german) vocabulary: 4587\n","Unique tokens in target (en) vocabulary: 4556\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sZ3fiLno60K_","executionInfo":{"status":"ok","timestamp":1610896845183,"user_tz":-480,"elapsed":932,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}}},"source":["word_2_idx = dict(e[2])\n","idx_2_word = {}\n","for k,v in word_2_idx.items():\n","  idx_2_word[v] = k"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"WunTmSIJzBaC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610896849270,"user_tz":-480,"elapsed":924,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"8f1a0c1d-862e-4b50-d494-c0ba2c966d99"},"source":["print(f\"Number of training examples: {len(train_data.examples)}\")\n","print(f\"Number of validation examples: {len(valid_data.examples)}\")\n","print(f\"Number of testing examples: {len(test_data.examples)}\")\n","\n","print(train_data[5].__dict__.keys())\n","pprint(train_data[5].__dict__.values())"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Number of training examples: 29000\n","Number of validation examples: 1014\n","Number of testing examples: 1000\n","dict_keys(['src', 'trg'])\n","dict_values([['a', 'man', 'in', 'green', 'holds', 'a', 'guitar', 'while', 'the', 'other', 'man', 'observes', 'his', 'shirt', '.'], ['a', 'man', 'in', 'green', 'holds', 'a', 'guitar', 'while', 'the', 'other', 'man', 'observes', 'his', 'shirt', '.']])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zRGP9EsizRRN","executionInfo":{"status":"ok","timestamp":1610896853092,"user_tz":-480,"elapsed":932,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","BATCH_SIZE = 32\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), \n","                                                                      batch_size = BATCH_SIZE, \n","                                                                      sort_within_batch=True,\n","                                                                      sort_key=lambda x: len(x.src),\n","                                                                      device = device)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"E3nozOT8zdeD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610896857410,"user_tz":-480,"elapsed":1027,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"f775d4b6-f0fa-4346-e713-76af9864d540"},"source":["count = 0\n","max_len_eng = []\n","max_len_ger = []\n","for data in train_data:\n","  max_len_ger.append(len(data.src))\n","  max_len_eng.append(len(data.trg))\n","  if count < 10 :\n","    print(\"German - \",*data.src, \" Length - \", len(data.src))\n","    print(\"English - \",*data.trg, \" Length - \", len(data.trg))\n","    print()\n","  count += 1\n","\n","print(\"Maximum Length of English sentence {} and German sentence {} in the dataset\".format(max(max_len_eng),max(max_len_ger)))\n","print(\"Minimum Length of English sentence {} and German sentence {} in the dataset\".format(min(max_len_eng),min(max_len_ger)))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["German -  two young , white males are outside near many bushes .  Length -  11\n","English -  two young , white males are outside near many bushes .  Length -  11\n","\n","German -  several men in hard hats are operating a giant pulley system .  Length -  12\n","English -  several men in hard hats are operating a giant pulley system .  Length -  12\n","\n","German -  a little girl climbing into a wooden playhouse .  Length -  9\n","English -  a little girl climbing into a wooden playhouse .  Length -  9\n","\n","German -  a man in a blue shirt is standing on a ladder cleaning a window .  Length -  15\n","English -  a man in a blue shirt is standing on a ladder cleaning a window .  Length -  15\n","\n","German -  two men are at the stove preparing food .  Length -  9\n","English -  two men are at the stove preparing food .  Length -  9\n","\n","German -  a man in green holds a guitar while the other man observes his shirt .  Length -  15\n","English -  a man in green holds a guitar while the other man observes his shirt .  Length -  15\n","\n","German -  a man is smiling at a stuffed lion  Length -  8\n","English -  a man is smiling at a stuffed lion  Length -  8\n","\n","German -  a trendy girl talking on her cellphone while gliding slowly down the street .  Length -  14\n","English -  a trendy girl talking on her cellphone while gliding slowly down the street .  Length -  14\n","\n","German -  a woman with a large purse is walking by a gate .  Length -  12\n","English -  a woman with a large purse is walking by a gate .  Length -  12\n","\n","German -  boys dancing on poles in the middle of the night .  Length -  11\n","English -  boys dancing on poles in the middle of the night .  Length -  11\n","\n","Maximum Length of English sentence 41 and German sentence 40 in the dataset\n","Minimum Length of English sentence 4 and German sentence 4 in the dataset\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pE_S5yMdwRsT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610896862766,"user_tz":-480,"elapsed":1561,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"4ab7e288-a398-4d0f-b066-decb8bb72ee7"},"source":["count = 0\n","for data in train_iterator:\n","  if count < 1 :\n","    print(\"Shapes\", data.src.shape, data.trg.shape)\n","    print()\n","    print(\"German - \",*data.src, \" Length - \", len(data.src))\n","    print()\n","    print(\"English - \",*data.trg, \" Length - \", len(data.trg))\n","    temp_ger = data.src\n","    temp_eng = data.trg\n","    count += 1"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Shapes torch.Size([12, 32]) torch.Size([14, 32])\n","\n","German -  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0') tensor([  4,  19,   4,  16,  16,   4,   4,   4,   4,   4,   4,   4,  21,   4,\n","          4,   7,   4,   4,   4,   4, 249,   4,   4,   9,   4,  16,   4,   4,\n","          4,   7,  21,   4], device='cuda:0') tensor([1042, 1168,    9,   23,   30,    9,    9,   35,   34,   38,   35,  209,\n","         103,   26,   32,    9,   33,   63,   63,   58,   49,  728,   34,   11,\n","          15,   24,   38,  199,   63, 2204, 1724,    9], device='cuda:0') tensor([   0,  873,  291,   62,   17,   10,  762,  121, 2213,   12,   10,  316,\n","         118,   35,  407,   10,  281,    6,   10,   38,    6,   13,  986,   49,\n","          90,  107,   12, 1422,    6,   35,    9,   11], device='cuda:0') tensor([1798,  128,    4,  192,  414,  161,   68,    8,   48,   19,   41,    0,\n","           6,  256,    4,   37,   10,  993, 2107,   12,  535,    4,    4,    6,\n","           8,   17,   30,  248,    4,   10,  753,    4], device='cuda:0') tensor([2934,   20,  651,    4,    6,    4,    7,    4,    4,  564,   79,  309,\n","           4,   18,  119,   13,  503,  418,   28,    0,   36,   33,   66,    4,\n","           4,  836,  730,    6, 2166,   78,    4,   15], device='cuda:0') tensor([2803,    4,   64,   29,   42, 1129, 1816,  283,  833,    6,    4,  784,\n","          33, 4226,   66,    7,   75,   77,   73, 2695,    6,  906,    6, 2303,\n","         949,   81,    4,  736,  121,  165,  993,  149], device='cuda:0') tensor([  48, 2444,   27,   11,   12,    6,   12,  328,    6,   21,  299,   13,\n","          80,   13,   28, 2365,    4,    4,   23,  741,    4, 1399,   27,  368,\n","          79,    6,  178,  220,  120,    4,   67,  228], device='cuda:0') tensor([   7,   20,  785,   60,    4,    7,   21,   48,    4,  700,   12,    4,\n","         161,    4,   31,   51,  552,  167,  123,  161, 2035,    4, 1125,  245,\n","           7,   24,   12,    4,   21,  285,   11,    4], device='cuda:0') tensor([ 235,  297, 1957,  292,  301,  233, 4281,  244,  114, 2490,   47,  376,\n","           4,   61,   40,   35,  914,   97,  194, 1233,  116, 1109,  181,    4,\n","          47,  557,  374,  160, 4281,  443,  565, 1442], device='cuda:0') tensor([  5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5, 335,  35,\n","          5,   5,   5,   5,   5,   5,   5,   5,   5, 561,   5,   5,   5,   5,\n","          5,   5,   5,   5], device='cuda:0') tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')  Length -  12\n","\n","English -  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0') tensor([  4,  19,   4,  16,  16,   4,   4,   4,   4,   4,   4,   4,  21,   4,\n","          4,   7,   4,   4,   4,   4, 251,   4,   4,   9,   4,  16,   4,   4,\n","          4,   7,  21,   4], device='cuda:0') tensor([ 812, 1170,    9,   24,   30,    9,    9,   35,   34,   38,   35,  216,\n","         106,   26,   33,    9,   31,   64,   64,   59,   50,  735,   34,   11,\n","          14,   25,   38,  198,   64,  386, 1729,    9], device='cuda:0') tensor([   0,  877,  296,   63,   17,   10,  768,  125, 2217,   12,   10,  323,\n","         120,   35,  411,   10,  276,    6,   10,   38,    6,   13,  996,   50,\n","          91,  112,   12, 1430,    6,   42,    9,   11], device='cuda:0') tensor([1801,  131,    4,  199,  419,  165,   69,    8,   49,   19,   41,    0,\n","           6,  260,    4,   37,   10, 1003, 2103,   12,  533,    4,    4,    6,\n","           8,   17,   30,  222,    4,  210,  761,    4], device='cuda:0') tensor([2936,   20,  663,    4,    6,    4,    7,    4,    4,  569,   80,  290,\n","           4,   18,  123,   13,  506,  421,   28,    0,   36,   31,   68,    4,\n","           4,  844,  737,    6, 2167,   35,    4,   14], device='cuda:0') tensor([2808,    4,   65,   29,   43, 1130, 1820,  288,  840,    6,    4,  786,\n","          31, 4201,   68,    7,   76,   78,   74, 2694,    6,  913,    6, 2309,\n","         959,   83,    4,  741,  125,   10, 1003,  152], device='cuda:0') tensor([  49, 2441,   27,   11,   12,    6,   12,  334,    6,   21,  303,   13,\n","          81,   13,   28, 2368,    4,    4,   24,  747,    4, 1404,   27,  372,\n","          80,    6,  184,  226,  124,   79,   67,  232], device='cuda:0') tensor([   7,   20,  787,   62,    4,    7,   21,   49,    4,  709,   12,    4,\n","         165,    4,   32,   53,  550,  170,  127,  165, 2035,    4, 1125,  252,\n","           7,   25,   12,    4,   21,  171,   11,    4], device='cuda:0') tensor([ 240,  305, 1961,  297,  299,  238, 4252,  250,  118, 2486,   47,  382,\n","           4,   61,   40,   35,  920,   99,  201, 1242,  119, 1111,  187,    4,\n","          47,  563,  377,  164, 4252,    4,  570, 1452], device='cuda:0') tensor([  5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5, 342,  35,\n","          5,   5,   5,   5,   5,   5,   5,   5,   5, 566,   5,   5,   5,   5,\n","          5, 287,   5,   5], device='cuda:0') tensor([  3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n","          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n","          3, 447,   3,   3], device='cuda:0') tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 5, 1, 1], device='cuda:0') tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 3, 1, 1], device='cuda:0')  Length -  14\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xSP5RchXyuaz","executionInfo":{"status":"ok","timestamp":1610896866360,"user_tz":-480,"elapsed":893,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}}},"source":["temp_eng_idx = (temp_eng).cpu().detach().numpy()\n","temp_ger_idx = (temp_ger).cpu().detach().numpy()"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"tgAmQS4I6k9v","colab":{"base_uri":"https://localhost:8080/","height":551},"executionInfo":{"status":"ok","timestamp":1610896869529,"user_tz":-480,"elapsed":1114,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"5af03751-18e9-4667-f4ac-b7653f4ad811"},"source":["\n","df_eng_idx = pd.DataFrame(data = temp_eng_idx, columns = [str(\"S_\")+str(x) for x in np.arange(1, 33)])\n","df_eng_idx.index.name = 'Time Steps'\n","df_eng_idx.index = df_eng_idx.index + 1 \n","# df_eng_idx.to_csv('/content/idx.csv')\n","df_eng_idx\n"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>S_1</th>\n","      <th>S_2</th>\n","      <th>S_3</th>\n","      <th>S_4</th>\n","      <th>S_5</th>\n","      <th>S_6</th>\n","      <th>S_7</th>\n","      <th>S_8</th>\n","      <th>S_9</th>\n","      <th>S_10</th>\n","      <th>S_11</th>\n","      <th>S_12</th>\n","      <th>S_13</th>\n","      <th>S_14</th>\n","      <th>S_15</th>\n","      <th>S_16</th>\n","      <th>S_17</th>\n","      <th>S_18</th>\n","      <th>S_19</th>\n","      <th>S_20</th>\n","      <th>S_21</th>\n","      <th>S_22</th>\n","      <th>S_23</th>\n","      <th>S_24</th>\n","      <th>S_25</th>\n","      <th>S_26</th>\n","      <th>S_27</th>\n","      <th>S_28</th>\n","      <th>S_29</th>\n","      <th>S_30</th>\n","      <th>S_31</th>\n","      <th>S_32</th>\n","    </tr>\n","    <tr>\n","      <th>Time Steps</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>19</td>\n","      <td>4</td>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>21</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>251</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>21</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>812</td>\n","      <td>1170</td>\n","      <td>9</td>\n","      <td>24</td>\n","      <td>30</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>35</td>\n","      <td>34</td>\n","      <td>38</td>\n","      <td>35</td>\n","      <td>216</td>\n","      <td>106</td>\n","      <td>26</td>\n","      <td>33</td>\n","      <td>9</td>\n","      <td>31</td>\n","      <td>64</td>\n","      <td>64</td>\n","      <td>59</td>\n","      <td>50</td>\n","      <td>735</td>\n","      <td>34</td>\n","      <td>11</td>\n","      <td>14</td>\n","      <td>25</td>\n","      <td>38</td>\n","      <td>198</td>\n","      <td>64</td>\n","      <td>386</td>\n","      <td>1729</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>877</td>\n","      <td>296</td>\n","      <td>63</td>\n","      <td>17</td>\n","      <td>10</td>\n","      <td>768</td>\n","      <td>125</td>\n","      <td>2217</td>\n","      <td>12</td>\n","      <td>10</td>\n","      <td>323</td>\n","      <td>120</td>\n","      <td>35</td>\n","      <td>411</td>\n","      <td>10</td>\n","      <td>276</td>\n","      <td>6</td>\n","      <td>10</td>\n","      <td>38</td>\n","      <td>6</td>\n","      <td>13</td>\n","      <td>996</td>\n","      <td>50</td>\n","      <td>91</td>\n","      <td>112</td>\n","      <td>12</td>\n","      <td>1430</td>\n","      <td>6</td>\n","      <td>42</td>\n","      <td>9</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1801</td>\n","      <td>131</td>\n","      <td>4</td>\n","      <td>199</td>\n","      <td>419</td>\n","      <td>165</td>\n","      <td>69</td>\n","      <td>8</td>\n","      <td>49</td>\n","      <td>19</td>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>260</td>\n","      <td>4</td>\n","      <td>37</td>\n","      <td>10</td>\n","      <td>1003</td>\n","      <td>2103</td>\n","      <td>12</td>\n","      <td>533</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>17</td>\n","      <td>30</td>\n","      <td>222</td>\n","      <td>4</td>\n","      <td>210</td>\n","      <td>761</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2936</td>\n","      <td>20</td>\n","      <td>663</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>569</td>\n","      <td>80</td>\n","      <td>290</td>\n","      <td>4</td>\n","      <td>18</td>\n","      <td>123</td>\n","      <td>13</td>\n","      <td>506</td>\n","      <td>421</td>\n","      <td>28</td>\n","      <td>0</td>\n","      <td>36</td>\n","      <td>31</td>\n","      <td>68</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>844</td>\n","      <td>737</td>\n","      <td>6</td>\n","      <td>2167</td>\n","      <td>35</td>\n","      <td>4</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2808</td>\n","      <td>4</td>\n","      <td>65</td>\n","      <td>29</td>\n","      <td>43</td>\n","      <td>1130</td>\n","      <td>1820</td>\n","      <td>288</td>\n","      <td>840</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>786</td>\n","      <td>31</td>\n","      <td>4201</td>\n","      <td>68</td>\n","      <td>7</td>\n","      <td>76</td>\n","      <td>78</td>\n","      <td>74</td>\n","      <td>2694</td>\n","      <td>6</td>\n","      <td>913</td>\n","      <td>6</td>\n","      <td>2309</td>\n","      <td>959</td>\n","      <td>83</td>\n","      <td>4</td>\n","      <td>741</td>\n","      <td>125</td>\n","      <td>10</td>\n","      <td>1003</td>\n","      <td>152</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>49</td>\n","      <td>2441</td>\n","      <td>27</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>6</td>\n","      <td>12</td>\n","      <td>334</td>\n","      <td>6</td>\n","      <td>21</td>\n","      <td>303</td>\n","      <td>13</td>\n","      <td>81</td>\n","      <td>13</td>\n","      <td>28</td>\n","      <td>2368</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>24</td>\n","      <td>747</td>\n","      <td>4</td>\n","      <td>1404</td>\n","      <td>27</td>\n","      <td>372</td>\n","      <td>80</td>\n","      <td>6</td>\n","      <td>184</td>\n","      <td>226</td>\n","      <td>124</td>\n","      <td>79</td>\n","      <td>67</td>\n","      <td>232</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>7</td>\n","      <td>20</td>\n","      <td>787</td>\n","      <td>62</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>21</td>\n","      <td>49</td>\n","      <td>4</td>\n","      <td>709</td>\n","      <td>12</td>\n","      <td>4</td>\n","      <td>165</td>\n","      <td>4</td>\n","      <td>32</td>\n","      <td>53</td>\n","      <td>550</td>\n","      <td>170</td>\n","      <td>127</td>\n","      <td>165</td>\n","      <td>2035</td>\n","      <td>4</td>\n","      <td>1125</td>\n","      <td>252</td>\n","      <td>7</td>\n","      <td>25</td>\n","      <td>12</td>\n","      <td>4</td>\n","      <td>21</td>\n","      <td>171</td>\n","      <td>11</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>240</td>\n","      <td>305</td>\n","      <td>1961</td>\n","      <td>297</td>\n","      <td>299</td>\n","      <td>238</td>\n","      <td>4252</td>\n","      <td>250</td>\n","      <td>118</td>\n","      <td>2486</td>\n","      <td>47</td>\n","      <td>382</td>\n","      <td>4</td>\n","      <td>61</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>920</td>\n","      <td>99</td>\n","      <td>201</td>\n","      <td>1242</td>\n","      <td>119</td>\n","      <td>1111</td>\n","      <td>187</td>\n","      <td>4</td>\n","      <td>47</td>\n","      <td>563</td>\n","      <td>377</td>\n","      <td>164</td>\n","      <td>4252</td>\n","      <td>4</td>\n","      <td>570</td>\n","      <td>1452</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>342</td>\n","      <td>35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>566</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>287</td>\n","      <td>5</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>447</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             S_1   S_2   S_3  S_4  S_5  ...  S_28  S_29  S_30  S_31  S_32\n","Time Steps                              ...                              \n","1              2     2     2    2    2  ...     2     2     2     2     2\n","2              4    19     4   16   16  ...     4     4     7    21     4\n","3            812  1170     9   24   30  ...   198    64   386  1729     9\n","4              0   877   296   63   17  ...  1430     6    42     9    11\n","5           1801   131     4  199  419  ...   222     4   210   761     4\n","6           2936    20   663    4    6  ...     6  2167    35     4    14\n","7           2808     4    65   29   43  ...   741   125    10  1003   152\n","8             49  2441    27   11   12  ...   226   124    79    67   232\n","9              7    20   787   62    4  ...     4    21   171    11     4\n","10           240   305  1961  297  299  ...   164  4252     4   570  1452\n","11             5     5     5    5    5  ...     5     5   287     5     5\n","12             3     3     3    3    3  ...     3     3   447     3     3\n","13             1     1     1    1    1  ...     1     1     5     1     1\n","14             1     1     1    1    1  ...     1     1     3     1     1\n","\n","[14 rows x 32 columns]"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"vXy1431M6o02","colab":{"base_uri":"https://localhost:8080/","height":551},"executionInfo":{"status":"ok","timestamp":1610896875052,"user_tz":-480,"elapsed":1001,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"e9d67c45-202d-475d-b716-2c0f3504c16f"},"source":["df_eng_word = pd.DataFrame(columns = [str(\"S_\")+str(x) for x in np.arange(1, 33)])\n","df_eng_word = df_eng_idx.replace(idx_2_word)\n","# df_eng_word.to_csv('/content/Words.csv')\n","df_eng_word"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>S_1</th>\n","      <th>S_2</th>\n","      <th>S_3</th>\n","      <th>S_4</th>\n","      <th>S_5</th>\n","      <th>S_6</th>\n","      <th>S_7</th>\n","      <th>S_8</th>\n","      <th>S_9</th>\n","      <th>S_10</th>\n","      <th>S_11</th>\n","      <th>S_12</th>\n","      <th>S_13</th>\n","      <th>S_14</th>\n","      <th>S_15</th>\n","      <th>S_16</th>\n","      <th>S_17</th>\n","      <th>S_18</th>\n","      <th>S_19</th>\n","      <th>S_20</th>\n","      <th>S_21</th>\n","      <th>S_22</th>\n","      <th>S_23</th>\n","      <th>S_24</th>\n","      <th>S_25</th>\n","      <th>S_26</th>\n","      <th>S_27</th>\n","      <th>S_28</th>\n","      <th>S_29</th>\n","      <th>S_30</th>\n","      <th>S_31</th>\n","      <th>S_32</th>\n","    </tr>\n","    <tr>\n","      <th>Time Steps</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","      <td>&lt;sos&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>a</td>\n","      <td>people</td>\n","      <td>a</td>\n","      <td>two</td>\n","      <td>two</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>an</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>the</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>five</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>man</td>\n","      <td>a</td>\n","      <td>two</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>the</td>\n","      <td>an</td>\n","      <td>a</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>chef</td>\n","      <td>serving</td>\n","      <td>man</td>\n","      <td>young</td>\n","      <td>men</td>\n","      <td>man</td>\n","      <td>man</td>\n","      <td>dog</td>\n","      <td>boy</td>\n","      <td>group</td>\n","      <td>dog</td>\n","      <td>construction</td>\n","      <td>asian</td>\n","      <td>black</td>\n","      <td>girl</td>\n","      <td>man</td>\n","      <td>red</td>\n","      <td>person</td>\n","      <td>person</td>\n","      <td>large</td>\n","      <td>women</td>\n","      <td>clown</td>\n","      <td>boy</td>\n","      <td>and</td>\n","      <td>woman</td>\n","      <td>white</td>\n","      <td>group</td>\n","      <td>horse</td>\n","      <td>person</td>\n","      <td>short</td>\n","      <td>overweight</td>\n","      <td>man</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>examination</td>\n","      <td>themselves</td>\n","      <td>takes</td>\n","      <td>children</td>\n","      <td>are</td>\n","      <td>is</td>\n","      <td>heads</td>\n","      <td>walks</td>\n","      <td>strolls</td>\n","      <td>of</td>\n","      <td>is</td>\n","      <td>worker</td>\n","      <td>lady</td>\n","      <td>dog</td>\n","      <td>throwing</td>\n","      <td>is</td>\n","      <td>truck</td>\n","      <td>in</td>\n","      <td>is</td>\n","      <td>group</td>\n","      <td>in</td>\n","      <td>with</td>\n","      <td>kicks</td>\n","      <td>women</td>\n","      <td>sits</td>\n","      <td>dogs</td>\n","      <td>of</td>\n","      <td>jockey</td>\n","      <td>in</td>\n","      <td>-</td>\n","      <td>man</td>\n","      <td>and</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>newly</td>\n","      <td>food</td>\n","      <td>a</td>\n","      <td>under</td>\n","      <td>laughing</td>\n","      <td>taking</td>\n","      <td>into</td>\n","      <td>on</td>\n","      <td>by</td>\n","      <td>people</td>\n","      <td>walking</td>\n","      <td>examination</td>\n","      <td>in</td>\n","      <td>trying</td>\n","      <td>a</td>\n","      <td>playing</td>\n","      <td>is</td>\n","      <td>protective</td>\n","      <td>breakdancing</td>\n","      <td>of</td>\n","      <td>dresses</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>in</td>\n","      <td>on</td>\n","      <td>are</td>\n","      <td>men</td>\n","      <td>covered</td>\n","      <td>a</td>\n","      <td>haired</td>\n","      <td>wears</td>\n","      <td>a</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>baked</td>\n","      <td>at</td>\n","      <td>break</td>\n","      <td>a</td>\n","      <td>in</td>\n","      <td>a</td>\n","      <td>the</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>gather</td>\n","      <td>near</td>\n","      <td>someone</td>\n","      <td>a</td>\n","      <td>to</td>\n","      <td>soccer</td>\n","      <td>with</td>\n","      <td>driving</td>\n","      <td>equipment</td>\n","      <td>while</td>\n","      <td>examination</td>\n","      <td>standing</td>\n","      <td>red</td>\n","      <td>ball</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>splashing</td>\n","      <td>enjoy</td>\n","      <td>in</td>\n","      <td>kilt</td>\n","      <td>dog</td>\n","      <td>a</td>\n","      <td>woman</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>popcorn</td>\n","      <td>a</td>\n","      <td>from</td>\n","      <td>blue</td>\n","      <td>front</td>\n","      <td>nap</td>\n","      <td>shadows</td>\n","      <td>path</td>\n","      <td>pond</td>\n","      <td>in</td>\n","      <td>a</td>\n","      <td>digging</td>\n","      <td>red</td>\n","      <td>mate</td>\n","      <td>ball</td>\n","      <td>the</td>\n","      <td>over</td>\n","      <td>riding</td>\n","      <td>some</td>\n","      <td>clothed</td>\n","      <td>in</td>\n","      <td>nose</td>\n","      <td>in</td>\n","      <td>halloween</td>\n","      <td>log</td>\n","      <td>around</td>\n","      <td>a</td>\n","      <td>mud</td>\n","      <td>walks</td>\n","      <td>is</td>\n","      <td>protective</td>\n","      <td>walk</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>by</td>\n","      <td>buffet</td>\n","      <td>his</td>\n","      <td>and</td>\n","      <td>of</td>\n","      <td>in</td>\n","      <td>of</td>\n","      <td>surrounded</td>\n","      <td>in</td>\n","      <td>an</td>\n","      <td>body</td>\n","      <td>with</td>\n","      <td>jacket</td>\n","      <td>with</td>\n","      <td>while</td>\n","      <td>shaggy</td>\n","      <td>a</td>\n","      <td>a</td>\n","      <td>young</td>\n","      <td>dancers</td>\n","      <td>a</td>\n","      <td>blows</td>\n","      <td>his</td>\n","      <td>costume</td>\n","      <td>near</td>\n","      <td>in</td>\n","      <td>day</td>\n","      <td>during</td>\n","      <td>along</td>\n","      <td>running</td>\n","      <td>hat</td>\n","      <td>past</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>the</td>\n","      <td>at</td>\n","      <td>hiking</td>\n","      <td>yellow</td>\n","      <td>a</td>\n","      <td>the</td>\n","      <td>an</td>\n","      <td>by</td>\n","      <td>a</td>\n","      <td>urban</td>\n","      <td>of</td>\n","      <td>a</td>\n","      <td>taking</td>\n","      <td>a</td>\n","      <td>sitting</td>\n","      <td>little</td>\n","      <td>rocky</td>\n","      <td>dirt</td>\n","      <td>boys</td>\n","      <td>taking</td>\n","      <td>lobby</td>\n","      <td>a</td>\n","      <td>living</td>\n","      <td>having</td>\n","      <td>the</td>\n","      <td>white</td>\n","      <td>of</td>\n","      <td>a</td>\n","      <td>an</td>\n","      <td>across</td>\n","      <td>and</td>\n","      <td>a</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>window</td>\n","      <td>night</td>\n","      <td>trip</td>\n","      <td>umbrella</td>\n","      <td>light</td>\n","      <td>train</td>\n","      <td>overpass</td>\n","      <td>trees</td>\n","      <td>park</td>\n","      <td>environment</td>\n","      <td>water</td>\n","      <td>machine</td>\n","      <td>a</td>\n","      <td>brown</td>\n","      <td>down</td>\n","      <td>dog</td>\n","      <td>surface</td>\n","      <td>bike</td>\n","      <td>watch</td>\n","      <td>photographs</td>\n","      <td>talking</td>\n","      <td>bubble</td>\n","      <td>room</td>\n","      <td>a</td>\n","      <td>water</td>\n","      <td>waves</td>\n","      <td>fishing</td>\n","      <td>race</td>\n","      <td>overpass</td>\n","      <td>a</td>\n","      <td>gloves</td>\n","      <td>storefront</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>photo</td>\n","      <td>dog</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>conversation</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>grassy</td>\n","      <td>.</td>\n","      <td>.</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>yard</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>.</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;eos&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","      <td>&lt;pad&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    S_1         S_2     S_3  ...     S_30        S_31        S_32\n","Time Steps                                   ...                                 \n","1                 <sos>       <sos>   <sos>  ...    <sos>       <sos>       <sos>\n","2                     a      people       a  ...      the          an           a\n","3                  chef     serving     man  ...    short  overweight         man\n","4           examination  themselves   takes  ...        -         man         and\n","5                 newly        food       a  ...   haired       wears           a\n","6                 baked          at   break  ...      dog           a       woman\n","7               popcorn           a    from  ...       is  protective        walk\n","8                    by      buffet     his  ...  running         hat        past\n","9                   the          at  hiking  ...   across         and           a\n","10               window       night    trip  ...        a      gloves  storefront\n","11                    .           .       .  ...   grassy           .           .\n","12                <eos>       <eos>   <eos>  ...     yard       <eos>       <eos>\n","13                <pad>       <pad>   <pad>  ...        .       <pad>       <pad>\n","14                <pad>       <pad>   <pad>  ...    <eos>       <pad>       <pad>\n","\n","[14 rows x 32 columns]"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"HLV-t-MzVQdg"},"source":["## 用 LSTM 搭建的 Encoder 類別: EncoderLSTM\n","\n"]},{"cell_type":"code","metadata":{"id":"0dZT3Zs17yMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610896889629,"user_tz":-480,"elapsed":1243,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"e50c1673-a9e4-4eb1-aa09-77381cd0726b"},"source":["class EncoderLSTM(nn.Module):\n","  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n","    super(EncoderLSTM, self).__init__()\n","\n","    # Size of the one hot vectors that will be the input to the encoder\n","    #self.input_size = input_size\n","\n","    # Output size of the word embedding NN\n","    #self.embedding_size = embedding_size\n","\n","    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n","    self.hidden_size = hidden_size\n","\n","    # Number of layers in the lstm\n","    self.num_layers = num_layers\n","\n","    # Regularization parameter\n","    self.dropout = nn.Dropout(p)\n","    self.tag = True\n","\n","    # Shape --------------------> (5376, 300) [input size, embedding dims]\n","    self.embedding = nn.Embedding(input_size, embedding_size)\n","    \n","    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n","    self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p)\n","\n","  # Shape of x (26, 32) [Sequence_length, batch_size]\n","  def forward(self, x):\n","\n","    # Shape -----------> (26, 32, 300) [Sequence_length , batch_size , embedding dims]\n","    embedding = self.dropout(self.embedding(x))\n","    \n","    # Shape --> outputs (26, 32, 1024) [Sequence_length , batch_size , hidden_size]\n","    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size]\n","    outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n","\n","    return hidden_state, cell_state\n","\n","input_size_encoder = len(german.vocab)\n","encoder_embedding_size = 300\n","hidden_size = 1024\n","num_layers = 2\n","encoder_dropout = 0.5\n","\n","encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,\n","                           hidden_size, num_layers, encoder_dropout).to(device)\n","print(encoder_lstm)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["EncoderLSTM(\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (embedding): Embedding(4587, 300)\n","  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JTew1tbHVer5"},"source":["## 用 LSTM 搭建的 decoder 類別: DecoderLSTM\n"]},{"cell_type":"code","metadata":{"id":"wPGbQiBP72iX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610896895432,"user_tz":-480,"elapsed":982,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"b4acf0b5-43ff-4922-8272-d903ae10906c"},"source":["class DecoderLSTM(nn.Module):\n","  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n","    super(DecoderLSTM, self).__init__()\n","\n","    # Size of the one hot vectors that will be the input to the encoder\n","    #self.input_size = input_size\n","\n","    # Output size of the word embedding NN\n","    #self.embedding_size = embedding_size\n","\n","    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n","    self.hidden_size = hidden_size\n","\n","    # Number of layers in the lstm\n","    self.num_layers = num_layers\n","\n","    # Size of the one hot vectors that will be the output to the encoder (English Vocab Size)\n","    self.output_size = output_size\n","\n","    # Regularization parameter\n","    self.dropout = nn.Dropout(p)\n","\n","    # Shape --------------------> (5376, 300) [input size, embedding dims]\n","    self.embedding = nn.Embedding(input_size, embedding_size)\n","\n","    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n","    self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p)\n","\n","    # Shape -----------> (1024, 4556) [embedding dims, hidden size, num layers]\n","    self.fc = nn.Linear(hidden_size, output_size)\n","\n","  # Shape of x (32) [batch_size]\n","  def forward(self, x, hidden_state, cell_state):\n","\n","    # Shape of x (1, 32) [1, batch_size]\n","    x = x.unsqueeze(0)\n","\n","    # Shape -----------> (1, 32, 300) [1, batch_size, embedding dims]\n","    embedding = self.dropout(self.embedding(x))\n","\n","    # Shape --> outputs (1, 32, 1024) [1, batch_size , hidden_size]\n","    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size] (passing encoder's hs, cs - context vectors)\n","    outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n","\n","    # Shape --> predictions (1, 32, 4556) [ 1, batch_size , output_size]\n","    predictions = self.fc(outputs)\n","\n","    # Shape --> predictions (32, 4556) [batch_size , output_size]\n","    predictions = predictions.squeeze(0)\n","\n","    return predictions, hidden_state, cell_state\n","\n","input_size_decoder = len(english.vocab)\n","decoder_embedding_size = 300\n","hidden_size = 1024\n","num_layers = 2\n","decoder_dropout = 0.5\n","output_size = len(english.vocab)\n","\n","decoder_lstm = DecoderLSTM(input_size_decoder, decoder_embedding_size,\n","                           hidden_size, num_layers, decoder_dropout, output_size).to(device)\n","print(decoder_lstm)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["DecoderLSTM(\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (embedding): Embedding(4556, 300)\n","  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n","  (fc): Linear(in_features=1024, out_features=4556, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xof3dPly753w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610896906284,"user_tz":-480,"elapsed":989,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"159bdc57-8c28-4d73-bd78-143ae9c0e187"},"source":["for batch in train_iterator:\n","  print(batch.src.shape)\n","  print(batch.trg.shape)\n","  break\n","\n","x = batch.trg[1]\n","print(x)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["torch.Size([9, 32])\n","torch.Size([9, 32])\n","tensor([ 290,   21,   21,    7,  113,   16,    4,    4,   16,    4,    4,   30,\n","           4,    4,    4,  161,   16,    4,    4,    4,   19,   19,   19,   63,\n","        2321,    4,    4,   16,   16,    4,    4,    4], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XGnQbCnGVire"},"source":["# Sequence to Sequence 類別"]},{"cell_type":"code","metadata":{"id":"_vzOor_Q782h","executionInfo":{"status":"ok","timestamp":1610896911198,"user_tz":-480,"elapsed":1483,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}}},"source":["class Seq2Seq(nn.Module):\n","  def __init__(self, Encoder_LSTM, Decoder_LSTM):\n","    super(Seq2Seq, self).__init__()\n","    self.Encoder_LSTM = Encoder_LSTM\n","    self.Decoder_LSTM = Decoder_LSTM\n","\n","  def forward(self, source, target, tfr=0.5):\n","    # Shape - Source : (10, 32) [(Sentence length german + some padding), Number of Sentences]\n","    batch_size = source.shape[1]\n","\n","    # Shape - Source : (14, 32) [(Sentence length English + some padding), Number of Sentences]\n","    target_len = target.shape[0]\n","    target_vocab_size = len(english.vocab)\n","    \n","    # Shape --> outputs (14, 32, 5766) \n","    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n","\n","    # Shape --> (hs, cs) (2, 32, 1024) ,(2, 32, 1024) [num_layers, batch_size size, hidden_size] (contains encoder's hs, cs - context vectors)\n","    hidden_state, cell_state = self.Encoder_LSTM(source)\n","\n","    # Shape of x (32 elements)\n","    x = target[0] # Trigger token <SOS>\n","\n","    for i in range(1, target_len):\n","      # Shape --> output (32, 5766) \n","      output, hidden_state, cell_state = self.Decoder_LSTM(x, hidden_state, cell_state)\n","      outputs[i] = output\n","      best_guess = output.argmax(1) # 0th dimension is batch size, 1st dimension is word embedding\n","      x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n","\n","    # Shape --> outputs (14, 32, 5766) \n","    return outputs\n"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywW6f9fM8AMa","executionInfo":{"status":"ok","timestamp":1610896940524,"user_tz":-480,"elapsed":7407,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}}},"source":["# Hyperparameters\n","\n","learning_rate = 0.001\n","writer = SummaryWriter(f\"runs/loss_plot\")\n","step = 0\n","\n","model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","pad_idx = english.vocab.stoi[\"<pad>\"]\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"yD0pRilG8CHJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610896947105,"user_tz":-480,"elapsed":1263,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"b166a35a-c23a-4f58-a664-a2d3918ff481"},"source":["model"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (Encoder_LSTM): EncoderLSTM(\n","    (dropout): Dropout(p=0.5, inplace=False)\n","    (embedding): Embedding(4587, 300)\n","    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n","  )\n","  (Decoder_LSTM): DecoderLSTM(\n","    (dropout): Dropout(p=0.5, inplace=False)\n","    (embedding): Embedding(4556, 300)\n","    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n","    (fc): Linear(in_features=1024, out_features=4556, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"fQyZ_vfq8G6C","executionInfo":{"status":"ok","timestamp":1610896952239,"user_tz":-480,"elapsed":941,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}}},"source":["def translate_sentence(model, sentence, german, english, device, max_length=50):\n","    spacy_ger = spacy.load(\"de\")\n","\n","    if type(sentence) == str:\n","        tokens = [token.text.lower() for token in spacy_ger(sentence)]\n","    else:\n","        tokens = [token.lower() for token in sentence]\n","    tokens.insert(0, german.init_token)\n","    tokens.append(german.eos_token)\n","    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n","    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n","\n","    # Build encoder hidden, cell state\n","    with torch.no_grad():\n","        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n","\n","    outputs = [english.vocab.stoi[\"<sos>\"]]\n","\n","    for _ in range(max_length):\n","        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n","\n","        with torch.no_grad():\n","            output, hidden, cell = model.Decoder_LSTM(previous_word, hidden, cell)\n","            best_guess = output.argmax(1).item()\n","\n","        outputs.append(best_guess)\n","\n","        # Model predicts it's the end of the sentence\n","        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n","            break\n","\n","    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n","    return translated_sentence[1:]\n","\n","# 用來評估模型的函式: bleu\n","def bleu(data, model, german, english, device):\n","    targets = []\n","    outputs = []\n","\n","    for example in data:\n","        src = vars(example)[\"src\"]\n","        trg = vars(example)[\"trg\"]\n","\n","        prediction = translate_sentence(model, src, german, english, device)\n","        prediction = prediction[:-1]  # remove <eos> token\n","\n","        targets.append([trg])\n","        outputs.append(prediction)\n","\n","    return bleu_score(outputs, targets)\n","\n","def checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss):\n","    print('saving')\n","    print()\n","    state = {'model': model,'best_loss': best_loss,'epoch': epoch,'rng_state': torch.get_rng_state(), 'optimizer': optimizer.state_dict(),}\n","    torch.save(state, './checkpoint-NMT')\n","    torch.save(model.state_dict(),'./checkpoint-NMT-SD')"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"ysc4A5HX8Qyg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610902455698,"user_tz":-480,"elapsed":5500058,"user":{"displayName":"TJ Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhD8ZNogaI1a7JvaPCP0sixRAUqrNuHydZOR0qLPQ=s64","userId":"07122505407861381538"}},"outputId":"efd952e3-e48a-432d-e8f1-db08759890b5"},"source":["epoch_loss = 0.0\n","num_epochs = 100\n","best_loss = 999999\n","best_epoch = -1\n","sentence1 = \"ein mann in einem blauen hemd steht auf einer leiter und putzt ein fenster\"\n","ts1  = []\n","\n","for epoch in range(num_epochs):\n","  print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n","  model.eval()\n","  translated_sentence1 = translate_sentence(model, sentence1, german, english, device, max_length=50)\n","  print(f\"Translated example sentence 1: \\n {translated_sentence1}\")\n","  ts1.append(translated_sentence1)\n","\n","  model.train(True)\n","  for batch_idx, batch in enumerate(train_iterator):\n","    input = batch.src.to(device)\n","    target = batch.trg.to(device)\n","\n","    # Pass the input and target for model's forward method\n","    output = model(input, target)\n","    output = output[1:].reshape(-1, output.shape[2])\n","    target = target[1:].reshape(-1)\n","\n","    # Clear the accumulating gradients\n","    optimizer.zero_grad()\n","\n","    # Calculate the loss value for every epoch\n","    loss = criterion(output, target)\n","\n","    # Calculate the gradients for weights & biases using back-propagation\n","    loss.backward()\n","\n","    # Clip the gradient value is it exceeds > 1\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","\n","    # Update the weights values using the gradients we calculated using bp \n","    optimizer.step()\n","    step += 1\n","    epoch_loss += loss.item()\n","    writer.add_scalar(\"Training loss\", loss, global_step=step)\n","\n","  if epoch_loss < best_loss:\n","    best_loss = epoch_loss\n","    best_epoch = epoch\n","    checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss) \n","    if ((epoch - best_epoch) >= 10):\n","      print(\"no improvement in 10 epochs, break\")\n","      break\n","  print(\"Epoch_Loss - {}\".format(loss.item()))\n","  print()\n","  \n","print(epoch_loss / len(train_iterator))\n","\n","# score = bleu(test_data[1:100], model, german, english, device)\n","# print(f\"Bleu score {score*100:.2f}\")"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Epoch - 1 / 100\n","Translated example sentence 1: \n"," ['launch', 'launch', 'service', 'service', 'rifle', 'clay', 'temple', 'temple', 'temple', 'temple', 'graduation', 'temple', 'temple', 'kneel', 'kit', 'bench', 'bench', 'mohawk', 'strike', 'strike', 'cloths', 'cloths', 'chefs', 'despite', 'despite', 'jars', 'bringing', 'bringing', 'screams', 'bringing', 'drop', 'screams', 'drop', 'examines', 'figure', 'figure', 'approximately', 'bmx', 'khaki', 'figure', 'navy', 'navy', 'approximately', 'few', 'drop', 'examines', 'figure', 'bear', 'bmx', 'bmx']\n","saving\n","\n","Epoch_Loss - 2.496891498565674\n","\n","Epoch - 2 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'with', 'with', '<unk>', '<unk>', 'and', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 2.2625880241394043\n","\n","Epoch - 3 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 2.0711746215820312\n","\n","Epoch - 4 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 1.4737868309020996\n","\n","Epoch - 5 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.9623785018920898\n","\n","Epoch - 6 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 1.7341171503067017\n","\n","Epoch - 7 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 1.1733043193817139\n","\n","Epoch - 8 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 1.0277745723724365\n","\n","Epoch - 9 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '\"', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.9333565831184387\n","\n","Epoch - 10 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', \"'s\", '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.3912426233291626\n","\n","Epoch - 11 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'i', 'i', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 1.7022349834442139\n","\n","Epoch - 12 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'i', 'i', 'i', 'i', 'i', '<unk>', '<unk>', '2', '2', '.', '<eos>']\n","Epoch_Loss - 1.202951431274414\n","\n","Epoch - 13 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'i', 'i', 'i', 'i', '<unk>', 'i', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.9736618995666504\n","\n","Epoch - 14 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', \"'s\", '<unk>', '<unk>', 'i', 'i', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 2.183181047439575\n","\n","Epoch - 15 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'i', 'i', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.3392554223537445\n","\n","Epoch - 16 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', 'i', 'i', 'i', '<unk>', 'still', \"'\", '<unk>', '2', '<eos>']\n","Epoch_Loss - 0.211518332362175\n","\n","Epoch - 17 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', 'new', '<unk>', '<unk>', 'i', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.8851438760757446\n","\n","Epoch - 18 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', \"'s\", '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.15140029788017273\n","\n","Epoch - 19 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', 'as', 'still', 'still', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.16479292511940002\n","\n","Epoch - 20 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', 'mid', '<unk>', '<unk>', 'i', 'shows', 'shows', '<unk>', 'practices', '<unk>', '<unk>', '2', '<unk>', '<eos>']\n","Epoch_Loss - 0.736193060874939\n","\n","Epoch - 21 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', 'mid', '<unk>', '<unk>', 'or', '<unk>', '<unk>', 'still', 'still', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.4109514355659485\n","\n","Epoch - 22 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'i', 'i', '<unk>', 'i', 'i', '<unk>', '<unk>', '2', '<unk>', '<eos>']\n","Epoch_Loss - 0.11506073921918869\n","\n","Epoch - 23 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'still', 'still', 'still', '<unk>', '2', '<unk>', '<eos>']\n","Epoch_Loss - 0.28256916999816895\n","\n","Epoch - 24 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', 'mid', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<unk>', '<eos>']\n","Epoch_Loss - 0.193191796541214\n","\n","Epoch - 25 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', 'this', '<unk>', '<unk>', 'i', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.2929207980632782\n","\n","Epoch - 26 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', 'mid', \"'s\", 'live', '<unk>', '<unk>', 'still', 'still', 'still', '<unk>', '2', '2', '<unk>', '<eos>']\n","Epoch_Loss - 0.33469268679618835\n","\n","Epoch - 27 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', 'i', '<unk>', 'still', 'still', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.2389441728591919\n","\n","Epoch - 28 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', 'i', 'still', 'still', 'still', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.11814472824335098\n","\n","Epoch - 29 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'i', '<unk>', 'i', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.1173534095287323\n","\n","Epoch - 30 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', \"'s\", 'shows', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<unk>', '<eos>']\n","Epoch_Loss - 0.18205717206001282\n","\n","Epoch - 31 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', \"'s\", '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<eos>']\n","Epoch_Loss - 0.8172231912612915\n","\n","Epoch - 32 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', 'mid', '<unk>', 'i', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.1357661336660385\n","\n","Epoch - 33 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.07731065899133682\n","\n","Epoch - 34 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', 'mid', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'still', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.19491194188594818\n","\n","Epoch - 35 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', 'mid', '-', '<unk>', 'shows', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<unk>', '<eos>']\n","Epoch_Loss - 1.2641268968582153\n","\n","Epoch - 36 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', 'european', '<unk>', '2', '<unk>', '\"', 'still', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.1073121502995491\n","\n","Epoch - 37 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', \"'s\", '<unk>', 'ears', '<unk>', '<unk>', 'assistant', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.47011053562164307\n","\n","Epoch - 38 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', 'still', 'still', 'still', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.05929488688707352\n","\n","Epoch - 39 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', 'store', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.4941180944442749\n","\n","Epoch - 40 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', 'mid', \"'s\", '<unk>', 'store', 'that', '<unk>', '<unk>', '<unk>', '2', '<unk>', '2', '<unk>', '<eos>']\n","Epoch_Loss - 0.06911133229732513\n","\n","Epoch - 41 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'store', 'have', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.5459222793579102\n","\n","Epoch - 42 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'called', 'that', 'still', '<unk>', 'still', 'still', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.21384672820568085\n","\n","Epoch - 43 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'store', '<unk>', '<unk>', '<unk>', '<unk>', 'still', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.22617344558238983\n","\n","Epoch - 44 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'store', 'store', '\"', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.11871776729822159\n","\n","Epoch - 45 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'store', '2', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<eos>']\n","Epoch_Loss - 0.15265467762947083\n","\n","Epoch - 46 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', 'mid', '-', '<unk>', '<unk>', 'as', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<unk>', '<eos>']\n","Epoch_Loss - 0.17177827656269073\n","\n","Epoch - 47 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.16555845737457275\n","\n","Epoch - 48 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'still', 'still', '<unk>', '2', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.0690036416053772\n","\n","Epoch - 49 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', \"'s\", 'school', 'that', '2', '<unk>', 'still', '<unk>', '<unk>', '2', '<eos>']\n","Epoch_Loss - 0.1515074074268341\n","\n","Epoch - 50 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'german', '2', '<unk>', '<unk>', 'still', 'still', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.358476459980011\n","\n","Epoch - 51 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'i', 'i', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'mind', '.', '<eos>']\n","Epoch_Loss - 0.12732960283756256\n","\n","Epoch - 52 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'i', 'mix', 'watch', '<unk>', 'still', 'still', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.03008074127137661\n","\n","Epoch - 53 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'still', 'still', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.095824234187603\n","\n","Epoch - 54 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', 'i', '<unk>', '<unk>', 'still', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.7458818554878235\n","\n","Epoch - 55 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'store', 'store', '\"', '<unk>', '\"', '<unk>', '<unk>', '<unk>', '2', '<eos>']\n","Epoch_Loss - 0.11445283889770508\n","\n","Epoch - 56 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', 'various', 'school', 'still', 'still', '<unk>', '<unk>', '2', '<eos>']\n","Epoch_Loss - 0.09745980054140091\n","\n","Epoch - 57 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', 'mid', '<unk>', '<unk>', '\"', 'that', '\"', 'still', 'still', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.091502845287323\n","\n","Epoch - 58 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'broken', '<unk>', 'what', '\"', 'still', 'still', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.09938091039657593\n","\n","Epoch - 59 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '\"', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.8095109462738037\n","\n","Epoch - 60 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '\"', 'sign', '\"', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.06929373741149902\n","\n","Epoch - 61 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', 'mom', 'that', '<unk>', 'bike', 'i', 'still', 'still', 'still', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.19222389161586761\n","\n","Epoch - 62 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', 'i', '<unk>', 'still', 'still', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.3183978796005249\n","\n","Epoch - 63 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', 'silver', 'still', 'still', 'still', 'still', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.04866161569952965\n","\n","Epoch - 64 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', 'lake', 'that', '<unk>', 'magazines', '<unk>', 'still', 'still', 'still', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.15666842460632324\n","\n","Epoch - 65 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', 'lake', '<unk>', 'that', 'i', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.09218292683362961\n","\n","Epoch - 66 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'still', 'still', 'still', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.46654072403907776\n","\n","Epoch - 67 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', 'live', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.055010367184877396\n","\n","Epoch - 68 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', 'that', 'shows', 'still', '<unk>', 'still', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.12448088079690933\n","\n","Epoch - 69 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', 'still', 'still', '<unk>', 'still', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.15521082282066345\n","\n","Epoch - 70 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '\"', 'meat', 'still', 'still', 'still', '<unk>', '<unk>', '2', '<eos>']\n","Epoch_Loss - 0.13429750502109528\n","\n","Epoch - 71 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', 'european', '<unk>', '<unk>', '\"', '<unk>', 'still', 'still', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.09532266855239868\n","\n","Epoch - 72 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', 'name', '<unk>', '<unk>', '<unk>', 'that', 'you', 'still', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.30613386631011963\n","\n","Epoch - 73 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'i', '<unk>', '\"', 'still', 'still', 'still', 'still', '<unk>', '2', '<eos>']\n","Epoch_Loss - 0.11906411498785019\n","\n","Epoch - 74 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'live', '<unk>', 'all', '<unk>', 'still', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.11339685320854187\n","\n","Epoch - 75 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'live', 'or', '<unk>', 'still', 'still', 'still', '<unk>', '<unk>', '2', '<eos>']\n","Epoch_Loss - 0.1830945611000061\n","\n","Epoch - 76 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '(', '<unk>', 'sign', 'still', 'still', 'still', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.11817879229784012\n","\n","Epoch - 77 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', 'truck', 'loading', 'sign', '<unk>', '<unk>', '<unk>', 'still', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.12114910781383514\n","\n","Epoch - 78 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', 'sign', 'or', '<unk>', 'still', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.06515931338071823\n","\n","Epoch - 79 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'or', 'that', '<unk>', '<unk>', '<unk>', 'still', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.08092513680458069\n","\n","Epoch - 80 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', 'jumpsuit', '<unk>', 'multicolored', '<unk>', 'or', '<unk>', 'still', '<unk>', '<unk>', '2', '<unk>', '<eos>']\n","Epoch_Loss - 0.3770601451396942\n","\n","Epoch - 81 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', 'fashion', '<unk>', '<unk>', '\"', '\"', '<unk>', 'still', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.0435849092900753\n","\n","Epoch - 82 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', 'wheelchair', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'still', 'still', 'still', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.12026262283325195\n","\n","Epoch - 83 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'live', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<unk>', '<eos>']\n","Epoch_Loss - 0.11868730932474136\n","\n","Epoch - 84 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'still', 'still', 'still', '<unk>', '<unk>', '.', '<eos>']\n","Epoch_Loss - 0.09292933344841003\n","\n","Epoch - 85 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'still', 'still', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.07611056417226791\n","\n","Epoch - 86 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<unk>', '<eos>']\n","Epoch_Loss - 0.38410457968711853\n","\n","Epoch - 87 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.12660275399684906\n","\n","Epoch - 88 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', 'ears', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.08535230159759521\n","\n","Epoch - 89 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '\"', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.3106864094734192\n","\n","Epoch - 90 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'store', '<unk>', 'sign', '\"', '<unk>', 'still', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.052768148481845856\n","\n","Epoch - 91 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', 'sign', '\"', '<unk>', 'still', 'still', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.17978112399578094\n","\n","Epoch - 92 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', 'digital', '<unk>', '<unk>', 'still', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.04589756950736046\n","\n","Epoch - 93 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'guy', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.1908547729253769\n","\n","Epoch - 94 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'jumpsuit', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<eos>']\n","Epoch_Loss - 0.0539117157459259\n","\n","Epoch - 95 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', 'sign', '<unk>', '<unk>', 'guy', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.0530635342001915\n","\n","Epoch - 96 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'still', '<unk>', '<unk>', '2', '<eos>']\n","Epoch_Loss - 0.36304140090942383\n","\n","Epoch - 97 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'making', '<unk>', '\"', '<unk>', '\"', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n","Epoch_Loss - 0.10326181352138519\n","\n","Epoch - 98 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', \"'s\", 'head', '<unk>', '\"', '<unk>', '\"', '<unk>', '<unk>', '<unk>', '2', '<unk>', '<eos>']\n","Epoch_Loss - 0.07914942502975464\n","\n","Epoch - 99 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'called', '<unk>', '<unk>', 'live', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.11678918451070786\n","\n","Epoch - 100 / 100\n","Translated example sentence 1: \n"," ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'german', '<unk>', 'sign', '<unk>', '\"', '<unk>', 'jersey', '<unk>', '<unk>', '<eos>']\n","Epoch_Loss - 0.06048065796494484\n","\n","35.35798271176215\n"],"name":"stdout"}]}]}