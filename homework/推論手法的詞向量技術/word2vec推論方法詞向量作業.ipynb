{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的: 了解為何需要推論方法的詞向量及其優缺點\n",
    "\n",
    "本次作業主要為思考題，請學員根據題目思考適合的回答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1:\n",
    "請學員思考為何不直接使用one-hot encoding的方式建立詞向量，而要有其他計數方法與推論方法的詞向量產生方式？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "若文本的詞彙不大，直接使用one-hot encoding的方式也是可以，但在做自然語言的題目時，文本的詞彙數量通常很龐大，如英文可能就有一百多萬個\n",
    "字詞，若只算母語是英文的人會使用的單字也接近20000 - 30000個字詞，將如此龐大的字詞轉化成one-hot encoding的形式，會造成詞向量太過稀\n",
    "疏(sparse vector)，在向量中有很多為零的值(不重要的)，因而導致在訓練時不好收斂。\n",
    "\n",
    "再者，one-hot encoding的方式無法表達字詞間的相關性(因為這些所有的one-hot向量都是orthogonal正交的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2:\n",
    "相較於計數手法的詞向量(ex: one-hot, 共現矩陣, PPMI)，word2vec的方法有何優點？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "1. Word2vec會考慮上下文，與計數手法比起來效果較好\n",
    "2. 若有新加入的字詞時，可以利用先前訓練好的模型當預訓練權重，而不需從頭開始訓練 (類神經網路的好處)\n",
    "3. 可以以小批次的訓練，因此文本很大時，也可以訓練\n",
    "4. 可以使用GPU進行加速運算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupoy_env",
   "language": "python",
   "name": "cupoy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
